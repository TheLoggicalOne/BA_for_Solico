{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Solico's Business Analytics Training","text":"<p>This is the course hub for the 14-week training program at Solico Group on:</p> <ul> <li>Business Analytics<ul> <li>Data Analysis</li> <li>Decision Modeling</li> </ul> </li> </ul>"},{"location":"#latest-updates-and-to-do","title":"Latest Updates and To Do","text":""},{"location":"#prepare-for-week-9","title":"Prepare for week 9","text":""},{"location":"#prepare-for-week-8-continue-working-on-previous-weeks-class-and-problem","title":"Prepare for Week 8, continue working on previous weeks class and problem","text":"<ul> <li>Continue working on week 6 page problems</li> <li> <p>Read chapter 5 and 6 of the book, specially:</p> <ul> <li>review summary of key terms for chapter 5, starting page 232</li> <li>review summary of key terms for chapter 6, starting page 280</li> </ul> </li> <li> <p>start working on week 8</p> </li> </ul>"},{"location":"#week-7","title":"Week 7","text":"<ul> <li>Here is links to jupyter notebooks files, in google drive:<ul> <li>Summary file: Focus on Big picture and components: From certainty to uncertainty<ul> <li>download file</li> <li>open in google colab</li> </ul> </li> <li>Detailed file with exapmles of how to work with distributions and results<ul> <li>download file</li> <li>open in google colab </li> </ul> </li> </ul> </li> <li>You can open above files directll in google colab, or download them and open them on your system  using jupyter notebook or vs code</li> </ul>"},{"location":"#prepare-for-week-6-continue-working-on-previous-weeks-class-and-problem","title":"Prepare for Week 6, continue working on previous weeks class and problem","text":"<ul> <li>start working on week 6 page</li> <li>Study Part 2 of the book:  <ul> <li>Chapter 5: Probability and probability distribution</li> <li>Chapter 6: Decision Making Under Uncertainty</li> </ul> </li> <li>Study Part 5 of the Book: <ul> <li>chapter 15.1 : Introduction to Simulation Modeling</li> <li>chapter 15.2 : Probability Distributions for Input Variables</li> <li>chapter 15.3 : Simulation and the Flaw of Averages  </li> <li>chapter 15.4 : Simulation with Built-in Excel Tools</li> </ul> </li> <li>Here is the Link to MIT Risk and Decision Analysis Course: IDS.333</li> <li>Please fill week 2,3 and 4 survey and self assesment here</li> <li>help us improve the course through General Feedback Form</li> </ul>"},{"location":"#prepare-for-week-5-continue-working-on-previous-weeks-class-and-problem","title":"Prepare for week 5, continue working on previous weeks class and problem","text":"<ul> <li>Here is the Link to MIT Risk and Decision Analysis Course: IDS.333</li> <li>start working on week 5 page </li> <li>Continue working on previous weeks problems</li> <li>Please fill week 2,3 and 4 survey and self assesment here</li> <li>help us improve the course through General Feedback Form</li> </ul>"},{"location":"#prepare-for-week-4-continue-on-week-3-class-and-prolems","title":"Prepare for week 4, Continue on week 3 class and prolems","text":"<ul> <li>start working on week 4 page </li> <li>Continue working on week 3 problems </li> </ul>"},{"location":"#prepare-for-week-3-continue-working-on-week-2-class-and-problems","title":"Prepare for Week 3 , Continue working on week 2 Class and Problems","text":"<ul> <li>Work on this spreadsheet online, you will see the problem with using percentages when quantities can be negative<ul> <li>I am not satisfied with how I explained this concept in class, I hope it will click when    you work with  numbers yourself</li> </ul> </li> <li>You can download all excel files form here (if you did not get them from Ms Tardast)</li> <li>start working on new problems in week 3 page </li> <li>You should start working on them as soon as possible, so that you could ask your question in Wednesday office hours</li> <li>Continue to think about problems in week 2 page</li> <li>Week 2 survey and quizz and some more problems will be added here Monday night</li> </ul>"},{"location":"#prepare-for-week-2","title":"Prepare for Week 2:","text":"<ul> <li>Go to week 2 page:<ul> <li>read the overview and goals</li> <li>start working on problems</li> </ul> </li> </ul>"},{"location":"#answer-to-week-one-survey-here","title":"Answer to week one survey here","text":""},{"location":"#what-should-you-do-as-a-learner","title":"What should you do as a learner?","text":"<ul> <li> <p>Check this page for latest updates and To Do</p> </li> <li> <p>Work on weekly problems and thinking problems</p> </li> <li>Find real problems in your life and your job that are really interesting to you, you could suggest your problem here:</li> <li>Constantly think about mathematical models that you use and their limitation in presenting real world factors and relations</li> <li> <p>Find an interesting projects to work on</p> </li> <li> <p>Help us make the course better by sharing your thought, suggestions, feedback and critique</p> <ul> <li>For General Feedback, Suggestions &amp; Critique go here</li> <li>Fill weekly survey and quizes , you could find them in each week page</li> </ul> </li> <li> <p>Be patient! Learning deep concepts is difficult and gradual, keep trying patiently, it will finally click. </p> </li> <li> <p>Think, Think, Think....Think about your thinking</p> </li> </ul>"},{"location":"mindset/","title":"The Mindset of a Modern Analyst","text":"<ul> <li>under progress</li> </ul> <p>Success in business analytics isn't just about mastering tools; it's about cultivating a mindset that can navigate complexity and uncertainty. The most common and costly errors in data analysis are rarely computational\u2014they are conceptual.</p> <p>This section is a guide to the core principles and common cognitive traps we will learn to overcome. We will see examples of these, expand on them and keep finding them in our journey</p>"},{"location":"mindset/#not-only-mastering-tools-is-easier-than-ever-it-has-becomealthough-debatable-unnecessary","title":"Not only mastering tools is easier than ever, it has become(although debatable) unnecessary","text":"<ul> <li>With the help of AI, and great advancment of softwares and tools, You don't have to memorize how to use different tools, you could just start using them</li> <li>But you should know what exactly those tool are doing, what is the meaning of their result, and how well these connect to problem you are solving or system that your are modeling</li> <li>For example, running a regression, is just couple of lines in sklearn, or couple of clicks in excel add-ins, or other tools...    <ul> <li>But to use regression for your real world problem, you shoould know what is regression, what are its assumption, and judge how well those assumptions hold in your problem</li> </ul> </li> <li> <p>Fitting a curve is one line in scipy, and feels like a superpower that enable us to predict everything, but its not</p> <ul> <li>It is true that mathematical formula have super power in fitting, they could fit everything! But this is the blessing and the curse, the problem is that mathematical formula fit the noise and systematic trends altoghther, since they all are the same thing to them</li> <li>Super power of </li> </ul> </li> <li> <p>Fortunately, all these methods, follow a simmilar framework:</p> </li> <li>computer programs and software and mathematics can only solve well-defined, clear problems, which are in their language: They understand logic, algorithms and mathematics</li> <li>To represent our real world problem, in their language, we need to do modeling</li> </ul>"},{"location":"mindset/#embrace-uncertainty","title":"Embrace Uncertainty","text":"<p>The real world is not a clean set of inputs and outputs. It's a dynamic system governed by randomness and incomplete information. Instead of trying to find the one thing that will happen, our goal is to understand the chances of different possibilities.</p> <ul> <li>The Future is a Distribution, Not a Number: A point forecast (\"we will sell 10,000 units\") is fragile. A probabilistic view (\"there's a 60% chance of selling between 8,000-12,000 units, but a 10% chance of selling less than 5,000\") is robust. It allows us to manage risk and make better decisions.</li> <li>The Power of Thinking in Ranges: This is a proven strategy. In professional poker, the best players stopped trying to guess their opponent's exact hand. They started thinking about their opponent's range of possible hands and used mathematics to play optimally against that entire range. They embraced uncertainty and dominated. Modern AI and machine learning algorithms operate on the same principle.</li> <li>see Embrace the uncertainty, even when there is none</li> </ul>"},{"location":"mindset/#a-field-guide-to-common-analytical-traps","title":"A Field Guide to Common Analytical Traps","text":"<p>We are all prone to being fooled by data. Here are some of the most common mistakes we will learn to identify and avoid.</p>"},{"location":"mindset/#fooled-by-numbers","title":"Fooled by Numbers","text":"<p>Numbers feel objective, but they are just a partial representation of reality. Is 100\u00b0F twice as hot as 50\u00b0F? Is a 100% increase in profit from $10 to $20 the same as from $1M to $2M? Understanding the context, scale (additive vs. multiplicative), and meaning behind a number is critical.</p>"},{"location":"mindset/#fooled-by-false-linearity","title":"Fooled by False Linearity","text":"<p>Planning based on the average outcome is one of the most dangerous traps in business. If you need a bridge to be 10 feet high on average, building it exactly 10 feet high will be a disaster\u2014half the time it will be too low! Decisions depend on the entire distribution of possibilities, not just the middle point.</p>"},{"location":"mindset/#fooled-by","title":"Fooled by","text":""},{"location":"mindset/#fooled-by-correlation","title":"Fooled by Correlation","text":"<p>Just because two things move together doesn't mean one causes the other. We'll learn to distinguish between coincidence, correlation, and true causation\u2014a skill essential for making interventions that actually work.</p>"},{"location":"mindset/#fooled-by-overfitting","title":"Fooled by Overfitting","text":"<p>It's easy to build a model that perfectly explains past data. It's much harder to build one that predicts the future. A model that is too complex and \"memorizes\" the noise in your data is useless for decision-making.</p>"},{"location":"mindset/#fooled-by-trying-to-predict-a-single-future","title":"Fooled by Trying to Predict a Single Future","text":"<p>This is the trap of non-Bayesian thinking. Instead of planning for one predicted reality, we should use data to update our beliefs about the likelihood of many possible futures and make decisions that are robust across them.</p>"},{"location":"mindset/#fooled-by-our-models","title":"Fooled by Our Models","text":"<p>George Box famously said, \"All models are wrong, but some are useful.\" We must never forget that our models are simplified representations of the world, not the world itself. Knowing a model's assumptions and limitations is as important as knowing how to build it.</p>"},{"location":"mindset/#fooled-by-randomness","title":"Fooled by randomness","text":""},{"location":"mindset/#fooled-by-base-rate-probabilities","title":"Fooled by base rate probabilities","text":""},{"location":"mindset/#fooled-by-hidden-assumption","title":"Fooled by hidden assumption","text":""},{"location":"mindset/#fooled-by-llm","title":"Fooled by LLM","text":""},{"location":"mindset/#fooled-by-local-fit","title":"Fooled by local fit","text":""},{"location":"projects/","title":"Projects &amp; Competition","text":"<p>The goal of this course is to build practical, applicable skills. The projects and competition are designed to help you apply the concepts we learn to solve realistic business problems.</p>"},{"location":"projects/#mini-projects","title":"Mini-Projects","text":"<p>Throughout the course, there will be 3+ mini-projects focused on applying specific analytical techniques (e.g., simulation, regression, optimization) to a business case. These will be guided exercises designed to build your confidence and modeling skills in Excel.</p> <p>I will provide constructive feedback and analysis of each participant's performance.</p>"},{"location":"projects/#the-solico-analytics-competition","title":"The Solico Analytics Competition","text":"<p>In the second half of the course, we will hold a friendly \"Kaggle-like\" internal competition.</p> <ul> <li>Goal: You will be given a real or synthetic dataset and a defined business objective.</li> <li>Task: Your team will analyze the data, build a model, and generate actionable insights.</li> <li>Evaluation: Teams will be evaluated not just on predictive accuracy, but on the interpretability, business impact, and communication of their models.</li> <li>Finale: The final results and team presentations will take place in Week 14.</li> </ul> <p>This is a chance to put everything together in a collaborative and competitive environment.</p>"},{"location":"projects/#best-problem-award","title":"\"Best Problem\" Award","text":"<p>To encourage real-world thinking and connect our learning directly to Solico's goals, we will have a \"Best Problem\" award.</p> <ul> <li>Submission Deadline: By the end of Week 5.</li> <li>Task: Each participant must propose one business problem or opportunity within Solico Group that could be addressed using the methods from this course.<ul> <li>You could suggest up to 3 problems, at different stages and choose the best one with our help</li> </ul> </li> <li>Criteria: The idea should be well-formulated (clearly defining the problem, the potential data, and the expected impact) and impactful.</li> <li>Award: The most impactful and well-formulated idea will win the Best Problem Award. This is a great opportunity to get expert feedback on a problem that matters to you and the company.</li> </ul>"},{"location":"resources/","title":"Resources &amp; Tools","text":"<p>This page will serve as a central hub for all supplementary materials shared throughout the course.</p>"},{"location":"resources/#supplementary-articles","title":"Supplementary Articles","text":"<p>As we cover new topics, I will post links to relevant articles and concept notes here. These are intended to provide deeper insight and real-world context beyond the textbook.</p> <ul> <li>Article 1: The Role of the Data Scientist in the Age of AI (Coming Soon)</li> </ul>"},{"location":"resources/#session-notes-and-slides","title":"Session Notes and Slides","text":""},{"location":"resources/#jupyter-notebooks","title":"Jupyter Notebooks","text":"<p>For certain topics, I will provide optional Jupyter (Python) Notebooks to demonstrate concepts visually or show an end-to-end analysis. These are for enrichment and do not require any programming knowledge to understand the key takeaways.</p> <ul> <li>Links to notebooks will be posted here as they become available.</li> </ul>"},{"location":"resources/#textbook-data","title":"Textbook Data","text":"<p>As mentioned in the syllabus, some proprietary data from the 7th edition of the textbook may not be available. When we cover examples from the book, I will provide links to the equivalent datasets we will be using here.</p> <ul> <li>Dataset links will be posted here.</li> </ul>"},{"location":"syllabus/","title":"Syllabus &amp; Course Structure","text":"<p>This page contains all the logistical details for our 14-week program.</p>"},{"location":"syllabus/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this course, you will be able to:</p> <ul> <li>Develop scientific thinking as a decision-making mindset.</li> <li>Understand the evolution of decision-making: from intuition to mathematical model and role of data analysis in discovery of probabilistic model.</li> <li>Frame business problems as decision problems under uncertainty.</li> <li>Think probabilistically: move from numbers to random variables, understand randomness, variation, and the role of distributions.</li> <li>Interpret statistical results (e.g., p-values, regression output) critically and in context.</li> <li>Use regression, simulation, and decision trees as part of a broader decision-making strategy.</li> <li>Move beyond predictive modeling to decision modeling.</li> <li>Build confidence in evaluating analyses, identifying flaws, and asking sharper questions.</li> <li>Translate business intuition into models\u2014and model results back into strategic decisions.</li> </ul>"},{"location":"syllabus/#course-logistics","title":"Course Logistics","text":"<p>\ud83d\uddd3 Schedule:</p> <ul> <li>14 weekly sessions \u00d7 3 hours :\u00a0<code>Every Satudray 10 - 13:15</code><ul> <li>Divided into Interactive + Lecture segments</li> </ul> </li> <li>14 Weekly Problem Solving / Office Hour Session: 1 hour\u00a0<code>Wednesday</code>\u00a0(Optional)  <ul> <li>problem solving and d competition strategy, and project discussion, exercises,  </li> </ul> </li> </ul> <p>\ud83d\udccdLocation:\u00a0Solico Group \ud83d\udcbc Format:</p> <ul> <li> <p>First 30 mins: Discussion &amp; case reflection  </p> </li> <li> <p>Lectures + Demos + Group activities  </p> </li> <li> <p>Hands-on Excel/Power BI/Spreadsheet work  </p> </li> </ul> <p>\ud83d\udcd5 Materials:</p> <ul> <li> <p>Business Analytics\u00a0textbook  </p> </li> <li> <p>Solico case studies (custom-prepared)  </p> </li> <li> <p>Spreadsheets &amp; datasets shared weekly</p> </li> </ul>"},{"location":"syllabus/#session-structure","title":"Session Structure","text":"<p>Each weekly lecture is divided into two structured parts:</p> <ul> <li> <p>Interactive Part: Delivered in a question-and-answer format, encouraging active participation, reflection, and discussion. This part draws out intuition and connects abstract ideas to real business logic.</p> <ul> <li>Usually first and last 10 minutes of each 1.5 hour Session will be interactive(at least)</li> </ul> </li> <li> <p>Lecture Part: Conceptual delivery similar to watching a video, with clear explanations, structured examples, and visual material. Questions are welcome, but will be answered at appropriate intervals to maintain the logical flow.</p> </li> </ul>"},{"location":"syllabus/#tentative-weekly-schedule","title":"Tentative Weekly Schedule","text":"Week Theme Topics 1 Kickoff &amp; The Big Picture Course philosophy, decision-making, models, uncertainty, role of AI 2 From Decision Making to Optimization Mathematical Modeling and Optimization, Linearity 3 Probability &amp; Decision Making Types of data, randomness, distributions, intuition-building 4 Statistical Inference I Sampling, confidence intervals, hypothesis testing 5 Probability Models &amp; Business Decisions Expected value, decision trees, payoff matrices 6 Risk &amp; Simulation Monte Carlo, uncertainty modeling, scenarios 7 Simulation Models Revisiting simulation, what-if tools, decision impact analysis 8 Regression I Basics, coefficients, interpretation, assumptions 9 Regression II Diagnostics, multicollinearity, real-world failure modes 10 Time Series Forecasting I Seasonality, moving averages, smoothing 11 Time Series Forecasting II ARIMA, planning under uncertainty 12 Optimization &amp; Allocation Linear programming, resource allocation, constraints 13 Causal Thinking &amp; Experiments A/B testing, confounding, causal logic, experimental design 14 Competition Finale &amp; Synthesis Group project presentations, critique, synthesis, feedback"},{"location":"syllabus/#materials-delivery","title":"Materials &amp; Delivery","text":"<ul> <li>Thinking Problems: To spark reflection, you'll receive a problem 3 days before each session.</li> <li>Weekly Slides: Conceptual lecture slides will be provided in English.</li> <li>Jupyter Notebooks (Optional): Select concepts will be illustrated using Python notebooks to showcase end-to-end workflows and highlight key lessons. No programming knowledge is required.</li> <li>Supplementary Articles: I will share articles to deepen your understanding.</li> <li>Lectures: All live lectures will be delivered in Farsi.</li> </ul>"},{"location":"syllabus/#assessment-feedback-anonymity","title":"Assessment, Feedback &amp; Anonymity","text":"<p>Your progress will be supported through practical exercises, projects, and a friendly competition. To encourage honest and thoughtful feedback, we will use an anonymous system for surveys and quizzes.</p> <ul> <li>At the start of the course, you will each choose a random unique ID (e.g., \"Falcon42\").</li> <li>Please use this same ID for all surveys and quizzes. This allows me to track learning progress while ensuring your psychological safety.</li> </ul>"},{"location":"syllabus/#note-on-book-data-and-tools","title":"Note on Book Data and Tools","text":"<p>The proprietary datasets from the 7th edition of the textbook are not fully available. Where necessary, I will recreat examples usi+ng equivalent public datasets or custom case studies relevant to Solico and the Iranian market. The course' learning value, which is based on conceptual thinking, will not be compromised.</p>"},{"location":"syllabus/#licensing-and-use-of-course-materials","title":"Licensing and Use of Course Materials","text":"<p>All original materials (slides, exercises, articles, code) developed for this course are copyrighted by the instructor  and are intended solely for use by registered participants. They may not be distributed, reproduced, or reused outside this program without prior written permission.</p>"},{"location":"concepts/","title":"Concepts and Principles","text":"<ul> <li>Flaw of Averages</li> <li>Linearity</li> <li>Scientific Method</li> </ul>"},{"location":"concepts/#under-progress-concept-and-principles-will-be-added-gradually","title":"Under Progress, concept and principles will be added gradually","text":""},{"location":"concepts/embrace_the_uncertainty/","title":"Embrace the Uncertainty, even when there is none!","text":""},{"location":"concepts/embrace_the_uncertainty/#the-flaw-of-averages","title":"The Flaw of Averages","text":""},{"location":"concepts/embrace_the_uncertainty/#gauess-invent-normal-distribution-as-distribution-of-error","title":"Gauess invent normal distribution as distribution of error","text":""},{"location":"concepts/embrace_the_uncertainty/#evolution-of-poker-from-magical-hand-reading-and-people-reading-skills-to-boring-mdf-and-gto","title":"Evolution Of Poker: From magical hand reading and people reading skills, to boring MDF and GTO","text":"<ul> <li>in many other imperfect information environments, it has been shown emprically, and could be shown through simulations that optimal thing to do is to make decision based on Bayesian Subjective </li> </ul>"},{"location":"concepts/embrace_the_uncertainty/#certainty-is-just-special-case-of-uncertainty","title":"Certainty, is just special case of uncertainty","text":"<ul> <li>variable is a very special case of random variable, when its distriution is dirac</li> </ul>"},{"location":"concepts/embrace_the_uncertainty/#is-quantom-physics-another-evidence","title":"Is Quantom Physics another evidence?","text":""},{"location":"concepts/flaw_of_averages/","title":"Flaw of averages","text":""},{"location":"concepts/flaw_of_averages/#summary","title":"Summary","text":"<ul> <li>as explained by de Neufville in MIT Decision Analysis ans Risk Management course</li> </ul>"},{"location":"concepts/flaw_of_averages/#what-is-it","title":"what is it?","text":"<ul> <li>a fundamental problem in the design and evaluation of projects</li> <li>The patern of designing, evaluating projects based on the average, \"most likely\" future forecast</li> <li>Derives from misunderstanding of probability and systems behavior</li> </ul>"},{"location":"concepts/flaw_of_averages/#the-name","title":"The name","text":"<ul> <li>A pun by Sam Savage(See the book \"Flaw of Averages, 2009\")</li> <li>A mistake -&gt; Flaw</li> <li>The concept of the \"Law of averages that things balance out on averages</li> </ul>"},{"location":"concepts/flaw_of_averages/#what-is-the-flaw","title":"What is the Flaw?","text":"<p>The error consist of assuming analyses based on \"average\" or \"most likely\" conditions give correct answer</p>"},{"location":"concepts/flaw_of_averages/#mathematics-of-flaw","title":"Mathematics of Flaw:","text":"<ul> <li>\\(E[f(x)] \\neq f(E(X))\\)</li> <li>See also Jensen Inequality</li> <li>where \\(E(x)\\) is expected value of \\(x\\)</li> </ul>"},{"location":"concepts/flaw_of_averages/#flaw-of-averages-in-words","title":"Flaw of averages in words","text":"<ul> <li>Average of all possible outcomes associated with uncertain parameters, generally does not equall the value obtained from using the average value of the parameters</li> </ul>"},{"location":"concepts/linearity/","title":"Linearity","text":"<p>Understanding how linear models express assumptions about constant tradeoffs and relative importance is fundamental to building intuition in business analytics.</p>"},{"location":"concepts/linearity/#module-modeling-objectives-as-linear-combinations-of-inputs","title":"\ud83e\udde0 Module: Modeling Objectives as Linear Combinations of Inputs","text":""},{"location":"concepts/linearity/#learning-goals","title":"\ud83c\udfaf Learning Goals:","text":"<ul> <li>Understand what it means to model an objective as a linear function of variables.</li> <li>Interpret coefficients in terms of marginal effects or weights.</li> <li>Explore hidden assumptions of linearity (e.g., constant tradeoffs, independence).</li> <li>Identify when linear models are reasonable, and when they fail.</li> </ul>"},{"location":"concepts/linearity/#what-is-a-linear-model","title":"\ud83e\uddee What is a Linear Model?","text":"<p>We model a target or objective (e.g. profit, cost, score, satisfaction) as:</p> <p>$ \\text{Objective} = w_1 x_1 + w_2 x_2 + \\dots + w_n x_n + b $</p> <p>Where:</p> <ul> <li>$ x_i $ : input variables (e.g., features of a product, price, time spent)</li> <li>$ w_i $ : weights or coefficients (value or cost per unit of each variable)</li> <li>$ b $ : baseline (intercept)</li> </ul>"},{"location":"concepts/linearity/#business-interpretation","title":"\ud83e\udde9 Business Interpretation","text":"<p>Each coefficient \\(w_i\\) answers:</p> <p>\u201cHow much does the objective change if we increase $ x_i $ by 1 unit, holding others constant?\u201d</p> <p>This implies:</p> <ul> <li>Constant marginal value: Each unit of $ x_i $ contributes exactly $ w_i $ more (or less) to the objective.</li> <li>Additivity: The effect of each variable is independent and adds up linearly.</li> <li>No interactions unless explicitly modeled.</li> </ul>"},{"location":"concepts/linearity/#hidden-assumptions-and-implications-of-linearity","title":"\u26a0\ufe0f Hidden Assumptions and Implications of Linearity","text":"Assumption Implication Real-World Concern Constant marginal value The tradeoff doesn\u2019t change Often unrealistic (e.g. diminishing returns) Additivity No interaction between variables But often variables interact (e.g. price and marketing) Linearity Simple decision surfaces But real-world systems often non-linear Perfect measurement No error, full observability Rarely true in practice"},{"location":"concepts/linearity/#example-1-advertising-budget-allocation","title":"\u2705 Example 1: Advertising Budget Allocation","text":""},{"location":"concepts/linearity/#problem","title":"Problem:","text":"<p>You want to model the sales as a function of spending in two channels: TV and Social Media.</p> <p>Assume:</p> <p>$ \\text{Sales} = 20 \\cdot \\text{TV} + 10 \\cdot \\text{Social} + 500 $</p>"},{"location":"concepts/linearity/#interpretations","title":"Interpretations:","text":"<ul> <li>Each $1 spent on TV increases sales by  $20.</li> <li>Each  $1 spent on Social increases sales by $10.</li> <li>The model assumes TV and Social have independent, constant effects.</li> </ul>"},{"location":"concepts/linearity/#questions","title":"Questions:","text":"<ul> <li>What if spending more on Social changes how effective TV is?</li> <li>What if the effect of TV tapers off after some amount?</li> </ul>"},{"location":"concepts/linearity/#example-2-product-feature-value","title":"\u2705 Example 2: Product Feature Value","text":"<p>A company makes custom laptops and assigns utility scores to features:</p> <p>$ \\text{Utility Score} = 50 \\cdot \\text{RAM(GB)} + 300 \\cdot \\text{SSD(GB)} + 100 \\cdot \\text{Battery(Hours)} $</p>"},{"location":"concepts/linearity/#assumptions","title":"Assumptions:","text":"<ul> <li>The value of 1GB RAM is always $50 \u2014 no matter how much RAM you already have.</li> <li>1 extra hour of battery is always worth $100 \u2014 even going from 1 \u2192 2 hours, or 9 \u2192 10.</li> </ul>"},{"location":"concepts/linearity/#but","title":"But\u2026","text":"<ul> <li>Users may value battery life more when it\u2019s low, and less when it's already high.</li> <li>Customers may only need \u201cenough\u201d SSD and value flattens after that.</li> </ul>"},{"location":"concepts/linearity/#example-3-linear-scoring-in-hr","title":"\u2705 Example 3: Linear Scoring in HR","text":"<p>A hiring team uses:</p> <p>$ \\text{Score} = 2 \\cdot \\text{Experience (Years)} + 3 \\cdot \\text{Education Level} + 1 \\cdot \\text{Skill Test Score} $</p> <p>Assumptions:</p> <ul> <li>1 year of experience is worth +2 points, always.</li> <li>1 more point in test score is worth +1 point in hiring score, regardless of baseline.</li> </ul>"},{"location":"concepts/linearity/#ask-yourself","title":"Ask Yourself:","text":"<ul> <li>Are these assumptions fair?</li> <li>Should the value of 5 years vs 6 years of experience be same as 1 vs 2?</li> </ul>"},{"location":"concepts/linearity/#visualization-idea","title":"\ud83d\udcc8 Visualization Idea","text":"<p>Use graphs to visualize the implication of linearity:</p> <ul> <li>Linear line: constant slope \u2192 constant rate of change</li> <li>Nonlinear: slope changes \u2192 diminishing/increasing returns</li> </ul>"},{"location":"concepts/linearity/#exercise-identify-linear-vs-nonlinear-behavior","title":"\ud83d\udcca Exercise: Identify Linear vs Nonlinear Behavior","text":"<p>Provide students with different objective formulas and ask:</p> <ul> <li>Is the relation linear?</li> <li>What does the coefficient mean?</li> <li>What\u2019s the assumption behind this coefficient?</li> </ul> <p>Example:</p> <ol> <li>$ \\text{Profit} = 100 \\cdot \\text{Units Sold} - 50 \\cdot \\text{Advertising Cost} $</li> <li>$ \\text{Satisfaction} = 50 \\cdot \\log(\\text{Speed}) + 100 \\cdot \\text{Design Quality} $</li> </ol> <p>Ask:</p> <ul> <li>Which one is linear?</li> <li>Where might it break?</li> </ul>"},{"location":"concepts/linearity/#summary-takeaways","title":"\ud83e\udde0 Summary Takeaways","text":"Insight Description Coefficients reflect value/tradeoff Interpret weights as marginal effects Linearity simplifies modeling But may hide real-world complexity Constant value = constant tradeoff Useful approximation, but verify Visualize to test reasonableness Plot input vs output to see relationships Nonlinearity is everywhere Linear models are starting points, not final truths"},{"location":"concepts/linearity/#optional-python-notebook-idea","title":"\ud83d\udce6 Optional: Python Notebook Idea","text":"<p>Use <code>matplotlib</code> and <code>numpy</code> to simulate and visualize:</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(0, 10, 100)\nlinear = 50 * x  # e.g., value of RAM in GB\nnonlinear = 300 * (1 - np.exp(-0.4 * x))  # diminishing returns\n\nplt.plot(x, linear, label=\"Linear (constant value)\")\nplt.plot(x, nonlinear, label=\"Nonlinear (diminishing returns)\")\nplt.xlabel(\"Input (e.g. RAM GB)\")\nplt.ylabel(\"Utility / Value\")\nplt.title(\"Linear vs Nonlinear Relationship\")\nplt.legend()\nplt.grid(True)\nplt.show()\n</code></pre>"},{"location":"concepts/scientific_method/","title":"Scientific method","text":""},{"location":"concepts/scientific_method/#the-foundation-of-knowing-the-scientific-method","title":"The Foundation of Knowing: The Scientific Method","text":"<p>Before we can analyze data, we need a reliable way to ask questions about the world. Our brains are incredible pattern-matching machines, but they are also flawed. We suffer from cognitive biases, like confirmation bias (seeing what we want to see) and finding illusory patterns in random noise.</p> <p>The scientific method isn't a magic formula; it's a rigorous process designed to protect us from fooling ourselves. It's a systematic way of asking questions and testing ideas to build reliable knowledge, whether in a physics lab or a business meeting. \ud83e\uddea</p> <p>We should see scientific method as a principled way of using our exprience and observations it helps us generalize and predict, using our exprience and data</p>"},{"location":"concepts/scientific_method/#the-core-loop-of-discovery","title":"The Core Loop of Discovery","text":"<p>The scientific method is a cycle of disciplined thinking. You can think of it as a loop that constantly refines our understanding. </p> <ol> <li> <p>Observation &amp; Question: It starts with noticing something interesting or puzzling.</p> <ul> <li>Science: \"Why do apples fall down but the moon stays up?\"</li> <li>Business: \"Our customer churn rate increased by 5% last quarter. Why?\"</li> </ul> </li> <li> <p>Hypothesis: You formulate a specific, testable explanation or prediction. A good hypothesis must be falsifiable\u2014meaning, there has to be a way to prove it wrong.</p> <ul> <li>Science: \"A force called gravity pulls objects with mass toward each other.\"</li> <li>Business: \"The churn rate increase was caused by the recent price hike.\"</li> </ul> </li> <li> <p>Experiment: You design a fair test to see if the evidence supports or contradicts your hypothesis. This is the most critical step. The goal is to isolate the one factor you're interested in and see what effect it has.</p> </li> <li> <p>Analysis &amp; Conclusion: You examine the results of your experiment.</p> <ul> <li>Does the evidence support the hypothesis? If so, your confidence in it grows.</li> <li>Does the evidence contradict the hypothesis? If so, you must either discard the hypothesis or revise it. This is not a failure! It's progress.</li> </ul> </li> <li> <p>Iteration: The conclusion of one experiment becomes the observation for the next. If the price hike wasn't the cause of churn, what is? A new cycle begins.</p> </li> </ol>"},{"location":"concepts/scientific_method/#the-heart-of-the-method-the-controlled-experiment","title":"The Heart of the Method: The Controlled Experiment","text":"<p>In most tests of economic theory, and certainly for evaluating business strategy, our goal is to infer that one variable (such as marketing spend) has a causal effect on another variable (such as sales). Simply finding an association between two variables might be suggestive, but unless causality can be established, it is rarely compelling.</p> <p>The notion of ceteris paribus\u2014which means \u201call other relevant factors being equal\u201d\u2014plays the most important role in causal analysis. For example, in analyzing consumer demand, we are interested in knowing the effect of changing the price of a good on its quantity demanded, while holding all other factors\u2014such as income, prices of other goods, and individual tastes\u2014fixed. If other factors are not held fixed, then we cannot know the true causal effect of a price change.</p> <ul> <li> <p>note: even in sensitivity analysis, we assume a cetris paribus frame work</p> </li> <li> <p>Cetris Paribus start from our question definition or our theory: Most of our theory, and questions that we ask, are cetris paribus in by nature</p> </li> </ul> <p>How do you design a \"fair test\" that achieves ceteris paribus? The gold standard is the controlled experiment. To design one, we must define our variables:</p> <ul> <li>Independent Variable: The one and only thing you intentionally change or manipulate. This is the presumed cause.</li> <li>Target(Dependent) Variable: The outcome you measure to see if the independent variable had an effect. This is the presumed effect.</li> <li>Controlled Variables: Everything else that could possibly influence the dependent variable. You must keep these constant to isolate the true effect of the independent variable.</li> </ul>"},{"location":"concepts/scientific_method/#example-a-simple-deterministic-experiment","title":"Example: A Simple Deterministic Experiment","text":"<p>Let's test a simple, non-random hypothesis where we can easily control the variables. * Question: Does the time it takes to boil water depend on the amount of water? * Hypothesis: More water will take longer to boil. * Independent Variable: The volume of water (1 liter vs. 2 liters). * Dependent Variable: The time it takes to reach 100\u00b0C. * Controlled Variables: The starting temperature of the water, the stove's heat setting, the pot used, and the atmospheric pressure.</p> <p>By keeping everything else the same (ceteris paribus), if the 2-liter pot takes longer to boil, you can be very confident it's because of the volume.</p>"},{"location":"concepts/scientific_method/#the-challenge-of-a-noisy-world-the-probabilistic-experiment","title":"The Challenge of a Noisy World: The Probabilistic Experiment","text":"<p>In business, biology, or marketing, we rarely have such clean, deterministic systems. The world is full of noise, which is the combination of many other unobserved and random factors. This noise is another variable we must control for. But how can we control for millions of random, unobserved factors like a customer's mood or their unique needs?</p> <p>We can't control them individually. However, thanks to the law of large numbers, we can manage their aggregate effect. This is where probability enters the process. Because we can only account for the effect of this noise probabilistically, we can only make probabilistic inferences about the results.</p>"},{"location":"concepts/scientific_method/#example-a-probabilistic-experiment","title":"Example: A Probabilistic Experiment","text":"<ul> <li>Question: Does our new website design (\"Version B\") lead to more sales than the old design (\"Version A\")?</li> <li>Hypothesis: Version B will have a higher average conversion rate.</li> <li>Independent Variable: The website design shown to the user (Version A or Version B).</li> <li>Dependent Variable: Whether the user makes a purchase.</li> <li>Uncontrolled Variables (Noise): The user's mood, budget, internet speed, whether they got distracted, etc.</li> </ul> <p>To run a fair test, we use two key techniques:</p> <ol> <li> <p>Control Group vs. Treatment Group: We split our subjects (website visitors) into two groups.</p> <ul> <li>Control Group: Sees the old design, Version A. This gives us a baseline for comparison.</li> <li>Treatment Group: Sees the new design, Version B.</li> </ul> </li> <li> <p>Randomization: We assign visitors to each group randomly. This is the magic ingredient! By randomizing, we don't eliminate the noise, but we ensure that it is, on average, evenly distributed between the two groups. Randomization turns all those uncontrollable factors into manageable random noise, allowing us to approximate a ceteris paribus condition.</p> </li> </ol> <p>Now, if we see a difference in the average conversion rate, we can be much more confident that it was caused by our independent variable (the website design) and not some other hidden factor.</p>"},{"location":"concepts/scientific_method/#what-the-scientific-method-demands-of-statistical-inference","title":"What the Scientific Method Demands of Statistical Inference","text":"<p>We can't just look at the results and say, \"Version B got 5.2% conversions and Version A got 5.0%, so B is better.\" That difference could just be the random noise we talked about!</p> <p>This is where the scientific method hands the baton to statistical inference. The principles of good experimental design inform how we must use our statistical tools:</p> <ol> <li> <p>The Need for Hypothesis Testing: Because of randomness, we need a formal way to decide if the observed difference between our groups is a real effect or if it could have plausibly happened by random chance alone. This is the entire purpose of hypothesis testing.</p> </li> <li> <p>The Logic of the Null Hypothesis: The principle of falsification is built directly into statistics. We start by assuming the skeptical hypothesis\u2014the Null Hypothesis (\\(H_0\\))\u2014is true (\"The new design has no effect\"). We then calculate how strange our observed result would be if that were the case.</p> </li> <li> <p>The Meaning of the P-value: The p-value is the tool that quantifies that \"strangeness.\" It's the probability of seeing a difference as large as the one we observed, assuming the null hypothesis is true. A small p-value tells us that our result is very surprising if there's truly no effect, giving us a reason to reject the null hypothesis.</p> </li> </ol> <p>In short, statistical inference is the mathematical toolkit for executing the scientific method in a world full of noise, randomness, and uncertainty. It gives us the rules for weighing evidence and making principled conclusions without fooling ourselves.</p>"},{"location":"weeks/","title":"Weekly Sessions Overview","text":"<p>Welcome to the detailed breakdown of our Solico course. Each week's session will have a dedicated page with learning objectives, materials, and activities.</p>"},{"location":"weeks/#course-schedule-content","title":"Course Schedule &amp; Content","text":"<ul> <li>Week 1: Kickoff &amp; The Big Picture<ul> <li>Session Details and Materials</li> <li>Introduction to course, book and Business Analytist in AI age.</li> <li>Week 1 survey</li> </ul> </li> <li> <p>Week 2: From Decision Making to Optimization</p> <ul> <li>Session Details and Materials</li> <li>Exploring the transition from qualitative decision-making to quantitative optimization.</li> <li>From Real World to a Mathematical Model</li> </ul> </li> <li> <p>Week 3: Optimization and Sensitivity Analysis, implied valuation</p> <ul> <li>Session Details and Materials</li> <li>Techniques for gathering and quantifying relevant data for decision models.</li> </ul> </li> <li> <p>... (Continue for all 14 weeks)</p> </li> <li> <p>Week 14: Final Projects &amp; Future of Solico</p> <ul> <li>Session Details and Materials</li> <li>Presentation of final projects and discussion on the broader applications of Solico.</li> </ul> </li> </ul>"},{"location":"weeks/draft/","title":"Draft","text":"<p>Here is a well-structured Week 4 course content draft based on your outline, expanded with added examples, explanations, and teaching strategies. It aims to:</p> <ul> <li>Connect intuition to modeling</li> <li>Emphasize the dangers of na\u00efve estimation</li> <li>Introduce expected value and optimization under uncertainty</li> <li>Deepen student understanding of how and why simulation and probability distributions matter</li> </ul>"},{"location":"weeks/draft/#week-4-decision-making-under-uncertainty-playing-the-averages-its-limits","title":"\ud83e\udde0 Week 4 \u2013 Decision Making Under Uncertainty: Playing the Averages &amp; Its Limits","text":""},{"location":"weeks/draft/#part-1-what-do-you-do-when-you-face-uncertainty","title":"\ud83e\udde9 Part 1 \u2013 What Do You Do When You Face Uncertainty?","text":"<p>Discussion prompt:</p> <p>Think of a time when you had to make a decision but didn\u2019t know all the facts. What did you do?</p>"},{"location":"weeks/draft/#real-world-examples-of-decisions-with-uncertainty","title":"\ud83d\udc40 Real-World Examples of Decisions with Uncertainty","text":"Decision Uncertain Variable Budgeting for next year Future income Hiring staff for a new branch Customer demand Advertising spend Conversion rate Stocking a new product Future sales volume Expanding a factory Future energy prices / market growth <p>\ud83d\udccc Class Activity: Ask students to give business examples from their own work experience where they had to guess or estimate an uncertain quantity.</p>"},{"location":"weeks/draft/#part-2-what-should-you-do","title":"\ud83e\uddea Part 2 \u2013 What Should You Do?","text":"<p>You have two choices:</p> <ol> <li>Ignore uncertainty (and hope for the best)</li> <li>Be scientific \u2014 use data and models to make better decisions</li> </ol> <p>\ud83d\udcac Narrative:</p> <p>Even the best experts cannot \u201cknow\u201d the future. But we can make educated guesses. If we gather data and understand the forces behind uncertainty, we can summarize uncertainty using probability distributions.</p>"},{"location":"weeks/draft/#part-3-playing-the-averages","title":"\ud83e\uddee Part 3 \u2013 Playing the Averages","text":""},{"location":"weeks/draft/#example-future-income","title":"Example: Future Income","text":"<p>You don\u2019t know your income next year. Based on past years and trends, you estimate:</p> Scenario Probability Income Low Market 0.2 120 million toman Normal 0.5 180 million toman Promotion or Project Win 0.3 250 million toman <p>\ud83c\udfaf Expected Value: \\(\\text{EV} = 0.2 \\times 120 + 0.5 \\times 180 + 0.3 \\times 250 = 186\\)</p> <p>So you use 186 million toman as your \"best guess\" and make all your financial plans based on it.</p>"},{"location":"weeks/draft/#part-4-but-wait-best-guess-for-what","title":"\ud83e\udd14 Part 4 \u2013 But Wait\u2026 \"Best Guess\" for What?","text":""},{"location":"weeks/draft/#important-concept","title":"\ud83e\udde0 Important Concept:","text":"<p>\"Best guess\" for an uncertain value is often just the number with least average error, not the one that gives you the best decision outcome.</p>"},{"location":"weeks/draft/#critical-distinction","title":"\ud83d\udce2 Critical Distinction:","text":"<ul> <li>Estimation Objective: Minimize error in guessing uncertain value</li> <li>Decision Objective: Maximize business outcome (e.g., profit)</li> </ul>"},{"location":"weeks/draft/#part-5-revisit-ncaa-t-shirt-problem-version-2","title":"\ud83d\udcc8 Part 5 \u2013 Revisit NCAA T-Shirt Problem (Version 2)","text":"<p>Demand is uncertain. In Version 2, we had:</p> <ul> <li>Three possible demand levels</li> <li>Probabilities associated with each</li> <li>We optimized based on expected demand</li> </ul> <p>\ud83c\udfaf Does this lead to the best decision?</p> <p>\u26a0\ufe0f Flaw of Averages:</p> <p>Using expected demand hides risk. You may choose a quantity that leads to large losses if demand is low or high.</p>"},{"location":"weeks/draft/#part-6-the-walton-bookstore-calendar-problem","title":"\ud83e\udde9 Part 6 \u2013 The Walton Bookstore Calendar Problem","text":"<p>(From book, Page 736)</p> <ul> <li>Cost: $7.50</li> <li>Selling price: $10</li> <li>Unsold refund: $2.50</li> <li>Demand is uncertain, average 200</li> </ul> <p>Q1: Should we order 200 calendars (the expected demand)?</p> <p>Use a probability distribution of demand and simulate or calculate expected profit for each possible order quantity.</p> <p>\ud83d\udcca Jupyter Notebook Suggestion: Let students simulate profits for order quantities of 150 to 250, under a triangular or normal distribution of demand centered at 200.</p>"},{"location":"weeks/draft/#part-7-when-does-playing-the-averages-work","title":"\ud83e\uddea Part 7 \u2013 When Does Playing the Averages Work?","text":"<p>\u2705 When:</p> <ul> <li>Your objective is linear in the uncertain quantity (e.g., profit = price \u00d7 demand)</li> <li>You have no downside or upside risk (e.g., over/understocking doesn\u2019t hurt much)</li> <li>The distribution is symmetric and narrow</li> </ul> <p>\u274c When:</p> <ul> <li>You face nonlinear costs or revenues</li> <li>Large downside risk (like overstocking calendars)</li> <li>Highly skewed or uncertain distributions</li> <li>Your objective involves probabilities, not just averages (e.g., minimizing chance of stockout)</li> </ul>"},{"location":"weeks/draft/#part-8-summary","title":"\ud83d\udd2e Part 8 \u2013 Summary","text":"<ul> <li>Decision making under uncertainty requires a distribution, not just a guess</li> <li>Expected value is useful, but not always optimal</li> <li>Many people (even pros) make decisions by \"playing the averages\"</li> <li>This works sometimes, but fails spectacularly in others</li> <li>Simulation is a powerful tool to understand the range of possible outcomes</li> </ul>"},{"location":"weeks/draft/#hands-on-assignment-jupyter-notebook-or-excel","title":"\ud83d\udcbb Hands-On Assignment (Jupyter Notebook or Excel)","text":"<ol> <li>Simulate the Walton Bookstore problem.</li> <li>Try three order quantities (e.g., 180, 200, 220).</li> <li>Use a normal or triangular distribution centered at 200.</li> <li>Estimate average profit from 1000 simulations for each.</li> <li>Which one has the best performance on average?</li> <li>What is the downside risk for each?</li> </ol>"},{"location":"weeks/draft/#class-discussion","title":"\ud83e\udde0 Class Discussion","text":"<ul> <li>Can you find examples where you or your company use the \"play the average\" strategy?</li> <li>Have you seen it backfire?</li> <li>How could you introduce probabilistic thinking into your daily or organizational decision-making?</li> </ul> <p>Would you like a ready-to-use Jupyter Notebook or Excel template to accompany this session?</p>"},{"location":"weeks/week01/","title":"Week 1: Kickoff &amp; The Big Picture","text":"<p>Welcome to our first session! Today, we lay the foundation for the entire course. We will explore the \"big picture\" of business analytics and connect the core pillars of decision-making, modeling, and uncertainty.</p>"},{"location":"weeks/week01/#session-goals","title":"Session Goals","text":"<ul> <li>Give a big picture of decision-making and its connection to optimization, probability, and simulation.</li> <li>Motivate the importance of building and understanding models.</li> <li>Address the role of business analytics in the age of AI.</li> <li>Establish the core mindset for the course: thinking with data.</li> </ul>"},{"location":"weeks/week01/#the-journey-from-decision-to-optimization","title":"The Journey: From Decision to Optimization","text":"<p>At its heart, every business decision involves three components:</p> <ol> <li> <p>A set of choices or actions you can take.</p> </li> <li> <p>A set of possible outcomes for each choice.</p> </li> <li> <p>A preference or valuation for each outcome (e.g., profit, cost, market share).</p> </li> </ol> <p>To analyze a decision scientifically, we must first represent it with a model\u2014a simplified, logical structure of the problem. When we define a clear, measurable objective (like maximizing profit or minimizing cost), the problem of making the \"best\" decision becomes an optimization problem. This is the foundational link between decision-making and a vast toolkit of mathematical methods.</p>"},{"location":"weeks/week01/#the-two-great-challenges-in-decision-making","title":"The Two Great Challenges in Decision Making","text":"<p>What makes decisions hard? It's not just about picking the highest number.</p>"},{"location":"weeks/week01/#1-complexity-even-with-certainty","title":"1. Complexity (Even with Certainty)","text":"<p>Even if you knew exactly what would happen for every choice, decisions can be incredibly complex. Your valuation of an outcome is rarely linear. -   Trade-offs: You can't maximize profit and quality and speed all at once. -   Diminishing Returns: The value of the 1000th unit sold is not the same as the value of the 1st. -   Constraints: You have limited budgets, time, and resources.</p>"},{"location":"weeks/week01/#2-uncertainty-the-real-world","title":"2. Uncertainty (The Real World)","text":"<p>This is the biggest challenge. After you make a choice, the final outcome is often random. -   You launch a product, but you don't know what competitor actions or economic shifts will occur. -   You invest in a stock, but its future price is uncertain.</p> <p>Your best choice depends on what could happen. This is where we must move beyond simple numbers and start thinking about probability distributions. The mathematical model of an uncertain future is not a single value, but a range of possibilities and their likelihoods.</p> <p>This is the motivation for simulation. If you had a superpower that let you live a thousand different lives for each choice you make, you could see all the potential outcomes and then come back to pick the choice that worked out best on average. Simulation gives our computers that superpower.</p>"},{"location":"weeks/week01/#the-elephant-in-the-room-why-not-just-use-ai","title":"The Elephant in the Room: Why Not Just Use AI? \ud83e\udd16","text":"<p>If AI is so powerful, why do we need to learn this? Why use Excel in the age of GPT?</p> <p>This is a critical question. The answer lies in the difference between complexity and conceptual depth.</p> <ul> <li>AI is brilliant at handling complexity. It can analyze millions of data points and find patterns no human ever could.</li> <li>AI lacks deep conceptual understanding. It cannot frame a business problem from scratch. It doesn't understand your company's strategic goals, the operational constraints of your factory, or the subtle needs of your customers. It can't tell you if you're measuring the right thing or if your model's assumptions match reality.</li> </ul> <p>AI is a powerful tool, like a sophisticated bulldozer. But you are the architect. You must decide where to dig, what to build, and whether the ground is stable. This course teaches you to be the architect, not just the bulldozer operator.</p>"},{"location":"weeks/week02/","title":"Week 2: From Decision Making to Optimization","text":""},{"location":"weeks/week02/#session-goals","title":"\ud83c\udfaf Session Goals","text":"<ul> <li>From Real World to a Mathematical Model</li> <li>From feelings and random judgments to metrics and valuations</li> <li>Show the big picture of decision making</li> <li>Emphasize the role of mathematical models in supporting decisions</li> <li>Discuss the limits and assumptions of models</li> <li>Position probability, statistics, and simulation in this process</li> <li>Reflect on what matters most in the AI age</li> <li>Engage participants with motivating problems that provoke thought</li> </ul> <p>\"All models are wrong, but some are useful.\" \u2013 George Box</p>"},{"location":"weeks/week02/#mini-intro-what-is-a-mathematical-model","title":"Mini Intro: \u201cWhat is a Mathematical Model?\u201d","text":""},{"location":"weeks/week02/#definition","title":"\ud83e\uddee Definition","text":"<p>A mathematical model is a simplified representation of a real-world situation using numbers, equations, relationships, or logic.</p> <p>Mathematical modeling is the art of translating real-world problems into the language of mathematics. The goal is to create a simplified representation of reality\u2014a \"model\"\u2014that helps us understand a problem, make predictions, or decide on a course of action. A model is like a map: it's not the actual territory, but it's incredibly useful for navigating it.</p> <p>The simplest model we have is a number. But even with something so simple, the choice of which number to use, and how to use it, is a critical part of the modeling process.</p>"},{"location":"weeks/week02/#all-models-simplify","title":"\u2702\ufe0f All models simplify","text":"<ul> <li> <p>We strip away some complexity to make problems tractable.</p> </li> <li> <p>We measure things with numbers (cost, growth, risk\u2026).</p> </li> <li> <p>Every model comes with assumptions \u2014 some are explicit, others hidden.</p> </li> </ul>"},{"location":"weeks/week02/#problems-to-think-about","title":"\ud83e\udde0 \ud83e\udde0 \ud83e\udde0 Problems to think about \ud83e\udde0 \ud83e\udde0 \ud83e\udde0","text":""},{"location":"weeks/week02/#problem-1","title":"Problem 1:","text":"<p>In each of following scenarios, try to make sense of numbers, explain what they say about real world, what are their limitation</p>"},{"location":"weeks/week02/#problem-1a-imagine-two-popular-youtubers","title":"\ud83e\udde0 Problem 1.a:  Imagine two popular YouTubers.","text":"<ul> <li> <p>Channel A has 10 million views on a video posted 2 years ago.</p> </li> <li> <p>Channel B has 1 million views on a video posted 1 week ago.</p> </li> </ul> <p>Think about it: Which channel is more \"successful\" right now? Why is simply comparing the tota  views (10 million vs. 1 million) a poor model for current popularity? What \"per unit\" model, like views per day, would be more useful?</p>"},{"location":"weeks/week02/#problem-1b-consider-two-companies-profits-last-year-and-this-year","title":"\ud83e\udde0 Problem 1.b: Consider two companies' profits last year and this year. \ud83d\udcc8","text":"<ul> <li> <p>We use numbers to describe growth or decline. But how we frame that change dramatically alters the story.</p> </li> <li> <p>Company A: Profit grew from \u20ac1 million to \u20ac2 million.</p> </li> <li> <p>Company B: Profit grew from \u20ac50 million to \u20ac55 million.</p> </li> </ul> <p>Think about it:</p> <ul> <li>Which company had a better performance?</li> <li>Which company had better CEO?</li> <li>Which one would you invest in?</li> </ul>"},{"location":"weeks/week02/#problem-1c-the-price-of-this-apartment-is-100m-toman-per-square-meter","title":"\ud83e\udde0 Problem 1.c:\ud83c\udff7\ufe0f \"The price of this apartment is 100M toman per square meter\"","text":"<p>\ud83d\udd39 What does \"per square meter\" mean here? \ud83d\udd39 Are all square meters equal? (corner units, sunlight, noise...) \ud83d\udd39 Does this average hide something important?</p>"},{"location":"weeks/week02/#problem-1d-under-president-obama-women-account-for-923-of-the-jobs-lost","title":"\ud83e\udde0 Problem 1.d: \ud83d\uddde\ufe0f  \u201cUnder President Obama, women account for 92.3% of the jobs lost.\u201d","text":"<p>In 2012, during the U.S. presidential campaign, Mitt Romney's team made this claim about jobs lost from January 2009 to March 2012.</p> <p>This was a real number, widely quoted, even repeated on news channels, and are correct according to  Bureau of Labor Statistics</p> <p>Indeed, men lost ~57,000 jobs, and women lost ~683,000 \u27a1\ufe0f So, 683k / (683k + 23k) \u2248 92.3% </p>"},{"location":"weeks/week02/#problem-1e-the-story-we-created-half-of-all-us-jobs","title":"\ud83e\udde0 Problem 1.e: \ud83d\udcd6 The Story: \u201cWe Created Half of All U.S. Jobs!\u201d","text":"<p>In June 2011, the Republican Party of Wisconsin put out a press release celebrating the state\u2019s economic success under Republican Governor Scott Walker. They claimed:</p> <p>\u201cWisconsin created half of all new jobs in America last month.\u201d</p> <p>Sounds incredible, right?</p>"},{"location":"weeks/week02/#problem-1f-example-comparing-three-apartments","title":"\ud83e\udde0 Problem 1.f: \ud83c\udfd8\ufe0f Example: Comparing Three Apartments","text":"Apartment Total Price (Toman) Area (m\u00b2) Price per m\u00b2 (Toman) A 4,800,000,000 60 80,000,000 B 6,000,000,000 75 80,000,000 C 6,800,000,000 100 68,000,000"},{"location":"weeks/week02/#problem-2-buying-a-car-whats-the-right-car-for-you","title":"\ud83e\udde0 Problem 2: \ud83d\ude97 : Buying a Car \u2013 What\u2019s the Right Car for You?","text":"<p>Do you need a car at all? If yes, which one should you buy?</p>"},{"location":"weeks/week02/#scenario","title":"Scenario","text":"<ul> <li>Assume that you are decision scientist and decision making expert, helping people to make best \"car buying decisions\".</li> <li>You are your first customer, </li> <li>How should you make this decision? How can you help other people in their \"car buying decisions\"?</li> <li>Can you convert this problem to a quantitative one?</li> </ul>"},{"location":"weeks/week02/#discussion-starters","title":"Discussion Starters","text":"<ul> <li>What criteria matter most to you? (e.g., price, cost, comfort, fuel efficiency, resale value, social status, safety, maintenance cost, long-term flexibility)</li> <li>Can you rank or assign weights to your preferences?</li> <li>Can you measure these things objectively? If not, how would you estimate them?</li> <li>What trade-offs are involved? (e.g., new car = peace of mind vs. used car = cheaper now)</li> <li>How would you model this decision?</li> </ul>"},{"location":"weeks/week02/#challenge","title":"Challenge","text":"<p>Build a simple multi-criteria decision model for your top 3 car options. Assign weights to your values and score each option.</p>"},{"location":"weeks/week02/#problem-3-which-loan-offer-should-you-take","title":"\ud83e\udde0 Problem 3: \ud83e\uddee Which Loan Offer Should You Take?","text":""},{"location":"weeks/week02/#scenario_1","title":"Scenario","text":"<ul> <li> <p>Assume that you are decision scientist and decision making expert, helping people to make best  \"financial decisions\".</p> <ul> <li>You are your first customer You need a loan of 1 billion toman. You have two offers:</li> </ul> </li> <li> <p>Bank A offers: 1B toman, repaid in 24 monthly installments of 60M each</p> </li> <li> <p>Bank B offers: 1B toman, repaid in 36 monthly installments of 45M each</p> </li> </ul> <p>You plug these into an IRR calculator(This is by far easiest part of the job in 2025)</p> <p>Bank A: Effective interest rate = 20% per year Bank B: Effective interest rate = 25% per year</p> <p>So: \u201cBank A is better. Lower interest.\u201d</p> <p>But is that the full story?</p>"},{"location":"weeks/week02/#discussion-starters_1","title":"Discussion Starters","text":"<ul> <li>What is IRR, and what does it mean in this context?</li> <li>Is interest rate the only factor that matters?</li> </ul>"},{"location":"weeks/week02/#challenge_1","title":"Challenge","text":"<p>How can you create a mathematical model for this problem that could find your real best choice?</p>"},{"location":"weeks/week02/#key-learning-themes","title":"Key Learning Themes","text":"<ul> <li>Time value of money (TVM), cash flow modeling</li> <li>Present value vs. internal rate of return</li> <li>Importance of context in interpreting model results</li> <li>Model limitations (e.g., assumes fixed future, ignores risk)</li> </ul>"},{"location":"weeks/week02/#problem-4-how-should-you-allocate-your-marketing-budget","title":"\ud83e\udde0 Problem 4: \ud83d\udcc8 How Should You Allocate Your Marketing Budget?","text":""},{"location":"weeks/week02/#scenario_2","title":"Scenario","text":"<p>You are the marketing lead for a product with a 100 Billion toman budget. You have 3 possible channels:</p> <ul> <li>Instagram influencers</li> <li>Search ads (Google)</li> <li>TV ads</li> </ul> <p>Your previous data shows:</p> Channel Cost per 1K reach Expected conversion rate Instagram 50K toman 4% Google 100K toman 9% TV 300K toman 2% <p>What should you do?</p>"},{"location":"weeks/week02/#discussion-starters_2","title":"Discussion Starters","text":"<ul> <li>How would you allocate your budget?</li> <li>What\u2019s your objective? Maximize conversions? Awareness? Long-term value?</li> <li>What assumptions are you making?</li> <li>What if your past data is biased or outdated?</li> <li>What about uncertainty or competitor response?</li> </ul>"},{"location":"weeks/week02/#challenge_2","title":"Challenge","text":"<p>How can you create a better mathematical model for this situation? You could even assume you have  more data</p>"},{"location":"weeks/week02/#problem-5-interactive-prompt","title":"\ud83e\udde0 Problem 5:\ud83d\udca1 Interactive Prompt","text":"<p>Think of a decision you or your team recently made.</p> <ul> <li>Did you use a model (even an informal one, or a process)?</li> <li>What was known vs. uncertain?</li> <li>How would a mathematical model help?</li> <li>What could it miss?</li> </ul>"},{"location":"weeks/week02/#problem-6-apartment-or-car-hunting","title":"\ud83e\udde0 Problem 6: \ud83c\udfe2 Apartment or Car Hunting","text":"<p>You\u2019re searching for undervalued deals of apartment or car(or in general, any other deal) Good ones show up and are taken quickly. If you wait, better ones might come, or you might end up with nothing.</p> <p>How many options should you review before choosing? How much should you wait?  How do you decide if a current deal is \u201cgood enough\u201d?</p>"},{"location":"weeks/week02/#challenge_3","title":"Challenge","text":"<p>How can you create a mathematical model for this problem? What data or info do you need?</p>"},{"location":"weeks/week02/#optional-follow-up-questions-all-problems","title":"\ud83e\udded Optional Follow-up Questions (All Problems)","text":"<ul> <li>What would you ask from a data analyst to help improve your decision?</li> <li>Can AI help you here? If so, what part of the decision? If not, why?</li> <li>What part of the decision needs human judgment?</li> </ul>"},{"location":"weeks/week03/","title":"Prepare for Week 3","text":""},{"location":"weeks/week03/#problems","title":"Problems","text":""},{"location":"weeks/week03/#revisit-example-11-of-the-bookpage-9-ordering-ncaa-t-shirts","title":"Revisit  EXAMPLE  1.1 of the book(page 9), ORDERING NCAA T-SHIRTS","text":"<ul> <li>This is the example that we worked in week 2 class, it is from the book, but we are generalizing it(as we did in class)</li> <li>Here is the question if you forgot:</li> </ul> Note <p>It is March, and the annual NCAA Basketball Tournament is down to the final four teams. Randy Kitchell is a T-shirt vendor who plans to order T-shirts with the names of the final four teams from a manufacturer and then sell them to the fans.The fixed cost of any order is $750, the variable cost per T-shirt to Randy is $8, and Randy\u2019s selling price is $18. However, this price will be charged only until a week after the tournament. After that time, Randy figures that interest in the T-shirts will be low, so he plans to sell all remaining T-shirts, if any, at $6 each.His best guess is that demand for the T-shirts during the full-price period will be 1500.He is thinking about ordering 1450 T-shirts, but he wants to build a spreadsheet model that will let him experiment with the uncertain demand and his order quantity. How should he proceed?</p> <ul> <li>we will consider five different version of this problem, in each of following versions explain:<ul> <li>what are inputs? </li> <li>what are decision variables?</li> <li>what is our exact objective? </li> </ul> </li> <li>You will need to use Excel, or Google Sheet, or LibreOffice or Python or...</li> </ul>"},{"location":"weeks/week03/#version-1-deterministic-demand","title":"Version 1: Deterministic demand","text":"<ul> <li>In first version, we are sure about future demand! we know for a fact that future demand will be 1500</li> <li>using a excel file that relates all variables together(this is spreadsheet model or mathematical model!) change value of different inputs and decision variable and see how objective changes</li> <li>find optimal choice for decision variable(the value for order that maximizes objective)</li> <li>How does changing fixed cost affect our choice?<ul> <li>How about sell price?</li> <li>How about variable cost?</li> <li>How about discount price?</li> </ul> </li> <li>Do you think relation between profit and variable cost is linear?<ul> <li>what about profit and fixed cost?</li> <li>what about profit and order?</li> <li>what about profit and demand?</li> </ul> </li> </ul>"},{"location":"weeks/week03/#version-2-three-way-fair-dice","title":"Version 2: Three way fair dice","text":"<ul> <li>In this version, we know for a fact that Demand will have only three possiblity, all of them equally likely</li> </ul> Scenario Demand Probability Low Interest 1,000 33.33% Medium Interest 1,500 33.33% High Interest 2,000 33.33% <ul> <li> <p>The data analyst, says that when we face a random variable, our best guess is its average value so we should assume demand is 1500, and we know when demand is 1500, best order is 1500</p> </li> <li> <p>some one else suggest that best order is 1800</p> </li> <li>How can you decide ( in a logical and pricncipled way) which choice is better? 1500 or 1800?</li> <li>What is our objective in this problem? Can you express all of our criteria and preferences in a single objective function?</li> <li>One crazy guy says that the best choice is to order 2000, can you convince him that he is wrong?</li> </ul>"},{"location":"weeks/week03/#version-3-three-way-unfair-dice","title":"Version 3: Three way unfair dice","text":"<ul> <li>In this version, we know for a fact that Demand will have only three possiblity, with following probailities</li> </ul> Scenario Demand Probability Low Interest 1,000 40% Medium Interest 1,500 35% High Interest 2,000 25%"},{"location":"weeks/week03/#version-4-unifrom-random","title":"Version 4: Unifrom Random","text":"<ul> <li>In this version, we know (for a fact!) that demand is a number between 500 to 2500, and it could be any of these numbers, all with same chance</li> <li>again, The data analyst, says that when we face a random variable, our best guess is its average value so we should assume demand is 1500, and then find optimal order for this demand<ul> <li>is he right?</li> </ul> </li> <li>what is the best choice for order?</li> <li>If we decrease the value of sell price , how does it affect optimal choice for order?</li> <li>for what value of sell price, our data analyst </li> </ul>"},{"location":"weeks/week03/#in-realityfuture-demand-is-uncertain-what-is-the-best-thing-we-could-hope-to-know-about-demand","title":"In reality,Future demand is uncertain, what is the best thing we could hope to know about demand?","text":"<ul> <li>How should we solve decision making problems that depend on future uncertain demand(or any other variable that is uncertain)?</li> </ul>"},{"location":"weeks/week03/#version-5-with-data","title":"Version 5: With data","text":"<ul> <li>in this version, we don't know anything magical about demand, the only thing that we know is history of our previus three years demand at the same event:</li> </ul> Year Demand 2024 1400 2023 2000 2022 1600 2021 1700"},{"location":"weeks/week03/#projecting-the-costs-of-bookshelves-at-woodworks","title":"PROJECTING THE COSTS OF BOOKSHELVES AT WOODWORKS","text":"<ul> <li>This is Example 1.2 from the book, its excel file name is <code>Bookshelf Costs Finished.xlsx</code> in chapter2 folder</li> <li>The Woodworks Company produces a variety of custom-designed wood furniture for its customers. One favorite item is a bookshelf, made from either cherry or oak. The company knows tha wood prices and labor costs are likely to increase in the future. Table 1.1 shows the number o board-feet and labor hours required for a bookshelf, the current costs per board-foot and labor hour, and the anticipated annual increases in these costs. (The top row indicates that either type of bookshelf requires 30 board-feet of wood and 16 hours of labor.) Build a spreadsheet model that enables the company to experiment with the growth rates in wood and labor costs so that a manage can see, both numerically and graphically, how the costs of the bookshelves increase in the next few years. </li> </ul> resource Cherry Oak Labor Required per bookshelf 30 30 16 Current unit cost $5.0 $4.30 $18.50 Anticipated annual cost increase 2.4% 1.7% 1.5% <ul> <li>What is the relation between total cost(projected cost) and year? How does increasing year affect total cost?</li> </ul>"},{"location":"weeks/week04/","title":"Prepare for Week 4","text":""},{"location":"weeks/week04/#week-4-decision-making-under-uncertainty-from-playing-the-averages-to-playing-the-distributions","title":"\ud83e\udde0 Week 4 \u2013 Decision Making Under Uncertainty: From Playing the Averages &amp; to Playing the distributions","text":""},{"location":"weeks/week04/#part-1-what-do-you-do-when-you-face-uncertainty-start-thiking","title":"\ud83e\udde9 Part 1 \u2013 What Do You Do When You Face Uncertainty? Start Thiking","text":"<ul> <li>Many of our decisions, depend on variables that are not deterministic, or even if they are, we don't know their value, so we are uncertain aout their value</li> </ul> <p>Think of a time when you had to make a decision but didn\u2019t know all the facts. What did you do?</p>"},{"location":"weeks/week04/#real-world-examples-of-decisions-with-uncertainty","title":"\ud83d\udc40 Real-World Examples of Decisions with Uncertainty","text":"Decision Uncertain Variable Budgeting for next year Future income Hiring staff for a new branch Customer demand Advertising spend Conversion rate Stocking a new product Future sales volume Expanding a factory Future energy prices / market growth"},{"location":"weeks/week04/#consider-following-scenario","title":"Consider following scenario","text":"<ul> <li>You want to decide how much money you should spend on apartment, car and other costs for next year for next year, but it all depends on your next year income<ul> <li>But you don't know how much you will make next year</li> <li>There are many uncertain factors that affect the income</li> </ul> </li> <li>find some more examples here, related to business</li> <li>what do you do this situation? what should you do?</li> <li> <p>Ask an expert, what will the expert do in this situation?</p> </li> <li> <p>We will make an educated guess for your income, and then solve a deterministic decision making problem, or a deterministic optimization problem</p> </li> <li>If you want to be more scientific, using data analysis and scientific method, you will find best estimate for your future income, which is usually average value of possible future incomes (where the average is taken over all possible future incomes, with wights equal to probability of each of them)</li> <li>There are many situations similar to this one, when your best choice deopends on values of some uncertain quantity. Find some of these situations in your job and your life. How do you handle those annoying uncertain values?</li> <li>When facing uncertainty, many people, even experts, try to find the best estimate(best guess) for uncertain quantity, which is usually the average value of that quantity, or its expected value, this strategy, is a famous one:<ul> <li>Playing the averages</li> </ul> </li> </ul>"},{"location":"weeks/week04/#consider-version-2-of-ordering-ncaa-t-shirts","title":"Consider version 2 of ORDERING NCAA T-SHIRTS","text":"<ul> <li>As we saw in version 2 of ORDERING NCAA T-SHIRTS in week 3 (review it here) demand is uncertain, and data analyst is suggesting to replace demand with our best estimate for demand, play the averages for demand, and then proceed and make the best choice assuming that demand is just our best guess(here, our best guess is a result of sound data analysis method)<ul> <li>Does this method find the optimal choice?</li> <li>Explain!</li> </ul> </li> </ul> Warning <p>be carefull when you say \"best estimate\" or \"best guess\", whenever you say best, you should ask  best in what? Best with respect to what? actually, any \"best\" relates to an objective, when talking about best estimate or best predecition, or best guess for a value, we are talking about best in terms of error, or accuracy...when we are saying best estimate for demand, we do not care about which demand is good or bad, we are just searching for a number, which has minimum error But when we say \"best choice\" , we mean the choice that maximize our decicion making objective! Yes, these are two different objective, for two different problems: For estimation of demand, our objective is minimizing error of our estimation(which is different form our main decision making objective)</p>"},{"location":"weeks/week04/#formulate-version-2-of-ordering-ncaa-t-shirts-as-an-optimization-problem","title":"Formulate version 2 of ORDERING NCAA T-SHIRTS as an optimization problem","text":"<ul> <li> <p>Can we formulate this problem as an optimization problem?</p> </li> <li> <p>If yes, what is the exact objective we are trying to maximize?</p> </li> <li>What assumptions are we making?</li> <li>How well this objective represent the reality?</li> <li>Is the final optimization problem deterministic or stochastic?</li> <li>Can we generalize method of solving this to other decision making under uncertainty problems? </li> </ul>"},{"location":"weeks/week04/#work-on-example-151-ordering-calendars-at-walton-bookstore-page-736-of-the-book","title":"Work on EXAMPLE  15.1 ORDERING CALENDARS AT WALTON BOOKSTORE page 736 of the book","text":"<p>In August, Walton Bookstore must decide how many of next year\u2019s nature calendars to order. Each calendar costs the bookstore $7.50 and sells for $10. After January 1, all unsold calendars will be returned to the publisher for a refund of $2.50 per calendar. Walton believes that the number of calendars it can sell by January 1 follows some probability distribution with mean 200. Walton believes that ordering to the average demand, that is, ordering 200 calendars, is a good decision. Is it?</p>"},{"location":"weeks/week04/#think-about-playing-the-averages","title":"Think about \"Playing The Averages\"","text":"<ul> <li>Can you find examples that you or others use this?</li> <li>How common is this used?</li> <li>How good is this strategy?</li> <li>When does this strategy work?</li> <li>Think about reasons and situations that this strategy fails </li> </ul>"},{"location":"weeks/week04/#what-do-you-do-when-you-face-uncertainty-do-not-fall-for-flaw-of-averages","title":"What Do You Do When You Face Uncertainty? Do not fall for flaw of averages","text":""},{"location":"weeks/week04/#summary","title":"Summary","text":"<ul> <li>as explained by de Neufville in MIT Decision Analysis ans Risk Management course</li> </ul>"},{"location":"weeks/week04/#what-is-it","title":"what is it?","text":"<ul> <li>a fundamental problem in the design and evaluation of projects</li> <li>The patern of designing, evaluating projects based on the average, \"most likely\" future forecast</li> <li>Derives from misunderstanding of probability and systems behavior</li> </ul>"},{"location":"weeks/week04/#the-name","title":"The name","text":"<ul> <li>A pun by Sam Savage(See the book \"Flaw of Averages, 2009\")</li> <li>A mistake -&gt; Flaw</li> <li>The concept of the \"Law of averages that things balance out on averages</li> </ul>"},{"location":"weeks/week04/#what-is-the-flaw","title":"What is the Flaw?","text":"<p>The error consist of assuming analyses based on \"average\" or \"most likely\" conditions give correct answer</p>"},{"location":"weeks/week04/#mathematics-of-flaw","title":"Mathematics of Flaw:","text":"<ul> <li>\\(E[f(x)] \\neq f(E(X))\\)</li> <li>See also Jensen Inequality</li> <li>where \\(E(x)\\) is expected value of \\(x\\)</li> </ul>"},{"location":"weeks/week04/#flaw-of-averages-in-words","title":"Flaw of averages in words","text":"<ul> <li>Average of all possible outcomes associated with uncertain parameters, generally does not equall the value obtained from using the average value of the parameters</li> </ul>"},{"location":"weeks/week04/#what-do-you-do-when-you-face-uncertainty-use-expected-value-of-your-deterministic-objective","title":"What Do You Do When You Face Uncertainty? Use expected value of your deterministic objective","text":"<ul> <li>In version 2 of NCCA Tshirt problem, instead of profit, we considered expected profit as our  ojective, and we find the order that maximizes this objective profit</li> <li>The expected monetary value, or EMV, for any decision is a weighted average of the possible payoffs/costs for this decision, weighted by the probabilities of the outcomes. Using the EMV criterion, you choose the decision with the largest EMV. This is sometimes called \u201cplaying the averages.\u201d</li> <li>If your objective is utility, use expected utility! more generally use \"expected value of objective</li> </ul>"},{"location":"weeks/week04/#are-you-ok-with-using-expected-manoetary-average-as-your-objective","title":"Are you ok with using Expected manoetary average as your objective?","text":"<ul> <li>consider version 2 of NCCA Tshirt problem</li> </ul>"},{"location":"weeks/week04/#the-prolem-is-beyond-risk","title":"The prolem is beyond risk","text":""},{"location":"weeks/week04/#your-real-objective-is-utility-not-money","title":"Your real objective is utility, not money","text":"<ul> <li>Even if you are risk neutral with respect to utility, just because of \"law of diminishing rate of return\" or convexity(non-linearity) of utility with respect to money (profit in NCCA Tshirt problem), you will still suffer from flaw of averages if you treat EMV is your ultimate objective, while your real objective is utility</li> <li>we are using money(profit) to represent our real objective which is actually utility. What really causes the problem is that utility has non-linear relation with money(more specifically convex)</li> <li>We should always be aware of convexity of utility(and many other objectives) with respect to different values. This is related to law of diminishing rate of retruns</li> <li>If you are thinking, for businesses, we don't have this problem, think again! </li> </ul>"},{"location":"weeks/week04/#your-real-objective-is-not-single-period-short-term","title":"Your real objective is not single period-short term","text":"<ul> <li>We are using static profit, a single period short-term profit</li> <li>What is our real objective?</li> <li>It is profit and value of our business not just this period, but for long run</li> <li>Again, the real problem is: Relation between long-term profit(our real objective) and short term profit(objective that we used) is non-linear and complex...so we are fooled y flaw of averages again....</li> </ul>"},{"location":"weeks/week04/#expected-value-is-only-for-your-final-ultimate-real-objective","title":"Expected value is only for your final ultimate real objective","text":""},{"location":"weeks/week04/#what-do-you-do-when-you-face-uncertainty-think-in-terms-of-random-variables-and-distribution","title":"What Do You Do When You Face Uncertainty? Think in terms of random variables and distribution","text":"<ul> <li>This is the right approach</li> <li>Consider NCCA Tshirt problem, we need to answer following questions:</li> <li>How likely is that:<ul> <li>Demand is lower than 1000</li> <li>Demand is lower than 500</li> <li>Demand is higher than 2000</li> <li>Profit is lower that 0</li> <li>Profit is lower than 5000</li> <li>Profit is higher than 10000</li> </ul> </li> <li>To make optimal decisions, and answer all the questions that we have, we need proability distribution of any variable of interest</li> </ul>"},{"location":"weeks/week04/#embrace-the-uncertainty","title":"Embrace the uncertainty","text":""},{"location":"weeks/week04/#what-do-you-do-when-you-face-uncertainty-create-a-magical-expriment-generator-device","title":"What Do You Do When You Face Uncertainty? Create a magical expriment generator device","text":"<ul> <li>yes simulation is the cheat code to exprience, and is more easier than ever thaks to probability and computer!</li> </ul>"},{"location":"weeks/week05/","title":"Prepare for Week 5","text":""},{"location":"weeks/week05/#problems","title":"Problems","text":""},{"location":"weeks/week05/#problem-1-solve-version-4-of-ncaa-t-shirt-problem","title":"Problem 1: Solve version 4 of NCAA T-shirt problem","text":"<ul> <li>Here is version 4</li> <li>You could do exactly what we did for version 3, only instead of 3 possible scenario for demand, consider 2000 possible scenario for demand!</li> <li>Remember,  if you could do it for more than one case, you could do it for 2000 or 2 million or cases!<ul> <li>This is one of super powers of spreadsheet or mathematical modeling using computer, </li> </ul> </li> <li>If you could do it one time, you could do it one billion time!</li> </ul>"},{"location":"weeks/week05/#problem-2-go-beyond-emv-in-version-4-of-ncaa-t-shirt-problem","title":"Problem 2: Go Beyond EMV in version 4 of NCAA T-shirt problem","text":"<ul> <li>Review how well EMV(expected monetary profit) represent our real world preferences and objectives</li> <li>in each of following cases, find the optimal order!</li> </ul>"},{"location":"weeks/week05/#version-41-fix-cost-for-low-profit","title":"version 4.1: Fix cost for low profit","text":"<ul> <li>If our profit falls below 8000, it will cost us another 1000$</li> </ul>"},{"location":"weeks/week05/#version-42-true-objective-is-function-of-profit","title":"version 4.2: True objective is function of profit","text":"<ul> <li>Our economist, did an extensive research, asking many questions from owners about how valuable is money in different situations, he finally claimed that:</li> <li>Profit is not our real objective, our real objective is utility, which itself can be seen as a function of profit</li> <li> <p>He also came up with the formula: $ U(m) = \\sqrt{m} $ , where $ U $ is our utility and $ U(m) $ is money or profit</p> </li> <li> <p>We accept his claim! Now find optimal order!</p> </li> <li> <p>You should Replace Profit or monetary value, with Utility which leads to replacing EMV with Expected Utility (EU)</p> </li> <li> <p>So basically, instead of: $$ \\text{Choose } x \\text{ to maximize } \\mathbb{E}[\\text{profit}(x)] $$</p> </li> <li> <p>You should: $$ \\text{Choose } x \\text{ to maximize } \\mathbb{E}[U(\\text{profit}(x))] $$</p> </li> <li> <p>You can simulate uncertain outcomes, compute utility of each, and then average them \u2192 just like with monetary profit, but now with utility instead of money.</p> </li> </ul>"},{"location":"weeks/week05/#problem-3-which-loan-offer-should-you-take","title":"\ud83e\udde0 Problem 3: \ud83e\uddee Which Loan Offer Should You Take?","text":""},{"location":"weeks/week05/#scenario","title":"Scenario","text":"<ul> <li> <p>Assume that you are decision scientist and decision making expert, helping people to make best  \"financial decisions\".</p> <ul> <li>You are your first customer You need a loan of 1 billion toman. You have two offers:</li> </ul> </li> <li> <p>Bank A offers: 1B toman, repaid in 24 monthly installments of 50M each</p> </li> <li> <p>Bank B offers: 1B toman, repaid in 48 monthly installments of 31M each</p> </li> </ul> <p>You plug these into an IRR calculator(This is by far easiest part of the job in 2025)</p> <p>Bank A: Effective interest rate = 20% per year Bank B: Effective interest rate = 23% per year</p> <p>Which one is better?  Try to solve this problem without any financial function or calculator, directly, from first princilples!</p>"},{"location":"weeks/week05/#problem-4-solve-version-6-of-ncaa-t-shirt-problem","title":"Problem 4: Solve version 6 of NCAA T-shirt problem!","text":""},{"location":"weeks/week05/#version-6-we-have-3000-potential-customer","title":"Version 6: We have 3000 potential customer","text":"<ul> <li>Each of them has a 50% chance of buying a T-shirt</li> <li> <p>what is the optimal order in this version?</p> </li> <li> <p>Is our assumption realistic? how can we make it more realistic?</p> </li> </ul>"},{"location":"weeks/week05/#problem-5-solve-combination-of-version-4-and-6-of-ncaa-t-shirt-problem","title":"Problem 5: Solve combination of version 4 and 6 of NCAA T-shirt problem!","text":""},{"location":"weeks/week05/#version-46","title":"version 46:","text":"<ul> <li>In this version, we know (for a fact!) that demand is a number between $ m-1000 $ to $ m+1000 $, and it could be any of these numbers, all with same chance </li> <li> <p>But we don't value of $ m $</p> </li> <li> <p>also,we know history of our previus three years demand at the same event:</p> </li> </ul> Year Demand 2024 1400 2023 2000 2022 1600 2021 1700 <ul> <li>what is the optimal order in this version? </li> <li>How real are our assumptions? How can we make them better?</li> </ul>"},{"location":"weeks/week05/#problem-6-solve-combination-of-version-5-and-6-of-ncaa-t-shirt-problem","title":"Problem 6: Solve combination of version 5 and 6 of NCAA T-shirt problem!","text":""},{"location":"weeks/week05/#version-56","title":"version 56:","text":"<ul> <li>we have 3000 potential customer, Each of them has a \\(p\\) chance of buying a T-shirt</li> <li>also,we know is history of our previus three years demand at the same event:</li> </ul> Year Demand 2024 1400 2023 2000 2022 1600 2021 1700"},{"location":"weeks/week05/#problem-7-work-on-example-151-ordering-calendars-at-walton-bookstore-page-736-of-the-book","title":"Problem 7: Work on EXAMPLE 15.1 ORDERING CALENDARS AT WALTON BOOKSTORE page 736 of the book","text":"<ul> <li>solve it Using excel file for NCAA T-shirt problem!</li> <li>could you generalize this frame work?</li> </ul>"},{"location":"weeks/week06/","title":"Prepare for Week 6","text":""},{"location":"weeks/week06/#problems","title":"Problems","text":""},{"location":"weeks/week06/#problem-1-what-do-you-think-about-flaw-of-averages-what-is-wrong-with-it","title":"Problem 1: What do you think about Flaw of Averages? What is wrong with it?","text":"<ul> <li>Find examples of Flaw of Averages,in personal and business decision making</li> </ul>"},{"location":"weeks/week06/#prolem-2-estimate-chance-of-success-of-bernouli-random-variable-from-data","title":"Prolem 2: Estimate chance of success of Bernouli random variable from data","text":"<ul> <li>$ X $ is a Bernouli random variable with probability of success equal to $ p $, p is unknown to us. in other words, $ P(X=1) = p $</li> <li>We know the result of one trial, which was success ( $ X=1 $)</li> <li>What can we say about \\(p\\)? How can we predict result of future trials of \\(X\\)?</li> <li>What if we know the result of more than one trials?</li> <li>Solve problem 6 of week 5</li> </ul>"},{"location":"weeks/week06/#problem-3-estimating-production-volume-from-single-data","title":"Problem 3: Estimating production volume from single data","text":"<ul> <li>Your competitor has started to produce a very special product. You want to know how many they have produced so far.</li> <li>Fortunately for you, they have numbered their productions: 1, 2, 3, ...You buy one, which is numbered 120<ul> <li>What can you say about their production volume?   </li> </ul> </li> <li> <p>You buy some more product, their numbers are: 33, 170, 220, 160...</p> <ul> <li>What can you say about their production volume?  </li> </ul> </li> <li> <p>Solve problem 5 of week 5</p> </li> </ul>"},{"location":"weeks/week06/#problem-4-conider-ncaa-t-shirt-problem-should-we-do-some-research-and-survey","title":"Problem 4: Conider NCAA T-shirt problem, Should we do some research and survey?","text":"<ul> <li>Consider the version where we know nothing about demand, is it a good idea to do some research?  </li> <li>How much should we spend on them?</li> </ul>"},{"location":"weeks/week06/#problem-5-you-are-playing-a-simple-dice-game","title":"Problem 5: you are playing a simple dice game:","text":"<ul> <li> <p>You throw a dice, if the result is $ x $, you will win $ x $ dollar. How much are you willing to pay for each round of this game? What is the maximum value? You could play as many rounds as you want</p> </li> <li> <p>What if the dice is not fair, let say has following chances</p> <ul> <li>$ P(D\\le 1) = 0.025 $</li> <li>$ P(D\\le 2) = 0.1 $</li> <li>$ P(D\\le 3) = 0.25$</li> <li>$ P(D\\le 4) = 0.475 $</li> <li>$ P(D\\le 5) = 0.725 $</li> <li>$ P(D\\le 6) = 1$</li> </ul> </li> </ul>"},{"location":"weeks/week06/#problem-6-consider-problem-5-of-week-5-how-valuable-is-information-or-data-here","title":"Problem 6: Consider problem 5 of week 5, how valuable is information or data here?","text":"<ul> <li>How much are you willing to pay, to know the value of $ m $</li> <li>How much are you willing to pay for each single sample of data?</li> </ul>"},{"location":"weeks/week06/#problem-7-quality-control-how-many-of-them-will-be-defective","title":"Problem 7: Quality control: How many of them will be defective?","text":"<ul> <li>You are a quality manager in a chocolate factory producing 10,000 chocolate bars per day.</li> <li> <p>Each bar has a probability $ p $ of being defective (air bubble, wrong weight, broken).</p> </li> <li> <p>Defective or not \u2192 This is a Bernoulli trial (success = defective, failure = good).</p> </li> <li> <p>The number of defectives in a batch follows a Binomial distribution:</p> </li> <li> <p>$ X \\sim \\mathrm{Binomial}(n,p) $</p> </li> <li>where: </li> <li>$ n  = \\text{number of inspected items}$</li> <li>$ p = \\text{probability of defect} $</li> </ul>"},{"location":"weeks/week06/#probability-perspective-known-p-predict-outcome","title":"Probability perspective (known p, predict outcome)","text":"<ul> <li> <p>Suppose $ p = 0.06 $ (6% defect rate)</p> </li> <li> <p>If we have  $ n = 100 $ inspected bars.</p> <ul> <li> <p>What\u2019s the probability of exactly 6 defectives?</p> </li> <li> <p>What\u2019s the probability of at most 6 defectives?</p> </li> <li> <p>What\u2019s the most likely number of defectives?</p> </li> <li> <p>What\u2019s the probability of at most 12 defectives?</p> </li> </ul> </li> <li> <p>We have a speciall customer that needs 100 good chocolate , how many choclate should we send her?</p> <ul> <li>If we want to be sure that there is 90 percent chance that she will have at least 100 good choclate? what about 90 percent? what about 99%?</li> </ul> </li> </ul>"},{"location":"weeks/week06/#statistics-perspective-unknown-p-estimate-from-sample","title":"Statistics perspective (unknown p, estimate from sample)","text":"<ul> <li>We don't the what percent of choclates are defective</li> <li>Is the percentage of defective choclate same as chance of being defective?</li> <li>How can we find these values? what can we say about them?</li> <li>Let say we can take samples from choclates, and inspect the</li> <li>To start, we inspect some choclates to find the first defective one</li> <li>After checking 78 choclates, the 79'th is defective<ul> <li>What can we say about chance of bieng defective</li> </ul> </li> <li>Let say we inspect more choclates, 500 of them in total and find out that $ x $ numbers of them are defective, what can we say about $ p $</li> </ul>"},{"location":"weeks/week06/#problem-8-work-on-example-59-from-the-book-is-this-mutual-fund-really-a-winner","title":"Problem 8: Work on Example 5.9 from the book: IS THIS MUTUAL FUND REALLY A WINNER?","text":"<ul> <li>An investment broker at the Michaels &amp; Dodson Company claims that he has found a real winner. He has tracked a mutual fund that has beaten a standard market index in 37 of the past 52 weeks. Could this be due to chance, or has he really found a winner?</li> <li>Objective  To determine the probability of a mutual fund outperforming a standard market index at least 37 out of 52 weeks</li> </ul>"},{"location":"weeks/week06/#problem-9-work-on-example-511-from-the-book-overbooking-by-airlines","title":"Problem 9: Work on Example 5.11 from the book: OVERBOOKING BY AIRLINES","text":"<ul> <li>This example presents a simplified version of calculations used by airlines when they overbook flights. They realize that a certain percentage of ticketed passengers will cancel at the last minute. Therefore, to avoid empty seats, they sell more tickets than there are seats, hoping that just about the right number of passengers show up.</li> <li> <p>We assume that the no-show rate is 10%. In binomial terms, we assume that each ticketed passenger, independently of the others, shows up with probability 0.90 and cancels with probability 0.10.</p> </li> <li> <p>For a flight with 200 seats, the airline wants to see how sensitive various probabilities are to the number of tickets it issues. In particular, it wants to calculate </p> <ul> <li>(a) the probability that more than 205 passengers show up</li> <li>(b) the probability that more than 200 passengers show up</li> <li>(c) the probability that at least 195 seats are filled, and </li> <li>(d) the probability that at least 190 seats are filled. </li> </ul> </li> <li> <p>The first two of these are \u201cbad\u201d events from the airline\u2019s perspective; they mean that some customers will be bumped from the flight. The last two events are \u201cgood\u201d in the sense that the airline wants most of the seats to be occupied.                                       </p> </li> </ul>"},{"location":"weeks/week08/","title":"Prepare for Week 8","text":""},{"location":"weeks/week08/#beyond-the-numbers-probabilistic-reasoning-for-business-analytics","title":"Beyond the Numbers: Probabilistic Reasoning for Business Analytics","text":"<ul> <li>Understanding P-values, Conditional Probability, and Why Common Sense is Your Best Tool</li> </ul>"},{"location":"weeks/week08/#our-approach-so-far-forward-problem","title":"Our Approach so far: Forward problem","text":"<ul> <li>So far we have discussed how to make deicison, assuming we know everything(at least up to distribution)</li> <li>Assuming we know mathematical model of system, and our preferences and distribution of variables, we have(hopefully) learned how to make decision</li> <li>But in real world, we dont know any of these</li> <li>Let first review the forward problem, and all the things we need for it</li> </ul>"},{"location":"weeks/week08/#to-solve-business-problem-and-make-optimal-choices-we-should","title":"To solve business problem, and make optimal choices, we should:","text":"<ul> <li>consider all possible choices: <ul> <li>set of choices, represented by variables</li> <li>This is a mathematical model of set choices!</li> </ul> </li> <li>compute reslut of each possible choice: <ul> <li>mathematical model that relates parameters, inputs, decision variables and outputs(results)</li> </ul> </li> <li> <p>evaluate and compare result of different choices(perfect-info judge)</p> <ul> <li>This is a metric to compare and evaluate choices</li> <li>Here we need a mathematical model of our preferences</li> <li>we should be able to evaluate and weigh pros and cons of different resluts</li> <li>we usually have multiple criteria</li> <li>Objective function: a way of representing our preferences over set of all possible results</li> <li>so we need a way of converting a multi criteria decision making problem to a single objective maximization problem</li> </ul> </li> <li> <p>evaluate and compare choices, without knowing the final outcome(imperfect-info judge)</p> <ul> <li>Imperfect information choice evaluator/metric:</li> <li>In presence of uncertainty, we don't see result of our choices, each choice will leads to distribution  of possible outcomes, so we should have decision rule, based on distribution of outcome, not the outcome itslef</li> </ul> </li> </ul>"},{"location":"weeks/week08/#in-other-words-we-need","title":"In other words we need:","text":"<ul> <li> <p>mathematical model of the system: variables and their relations: represent relation between variables(inputs, outputs)</p> <ul> <li>In deterministic case, we model variables using numbers, so we talk about their values</li> <li>In presence of uncertainty, we model variables using random variable, so we talk about  distribution of value   </li> </ul> </li> <li> <p>mathematical model of our preferences and descion making: </p> <ul> <li>algorithm to compare and evaluate choices:</li> <li>perfect-info algorithm , which can rank and score different finall outcomes</li> <li>imperfect info algorithm, which can compare choices, without even knowing the finall outcome, these algorithm should decide based on distribution of outcomes actually, we could consider our objective as another variable, but since it depends on our subjective</li> </ul> </li> <li> <p>Deterministic vs stochastic</p> <ul> <li>variales vs random variable</li> <li>value of input vs distribution of values of input</li> <li>value of output vs distribution of values of outputs</li> <li>preferences over outcomes vs preferences over distribution of outcomes\\</li> <li>value of objective vs distribution of value of objective</li> </ul> </li> </ul>"},{"location":"weeks/week08/#from-perfect-info-choice-evaluatorjudge-to-imperfect-info-choice-evaluatorjudge","title":"From Perfect-Info Choice evaluator(Judge), to Imperfect-Info choice evaluator(judge)","text":"<ul> <li>From prefernces over deterministic objective to preferences over distribution of objective</li> <li>Most common approach is considering expected value of objective<ul> <li>wokrs great if, your objective is your real objective! As represented bu numbers:<ul> <li>$ 15100 - 15000 = 8100 - 8000 = 1100 - 1000 $</li> <li>$ 2 * 10000 = 20000 $</li> <li>in a way that  </li> </ul> </li> <li>Suffer from flaw of averages if, your real objective is non-linear function of this objective</li> <li>It is not enough to have a objective function that is rank-consistent with your preferences</li> </ul> </li> </ul>"},{"location":"weeks/week08/#to-reality-inverse-problem","title":"To Reality: Inverse Problem","text":"<ul> <li> <p>To solve a business problem, we need to know:</p> <ul> <li>relations between variables</li> <li>distribution of inputs</li> <li>distribution of outputs</li> <li>distribution of objectives</li> <li>which distribution of outputs we prefer</li> <li>Our preferences over outputs and distribution of outputs</li> </ul> </li> <li> <p>If we know all of these things, we are facing a simple forward problem:</p> </li> <li>froward Problem: we know the system, and what it does on its input. Given each set of inputs,  we can compute output of the system</li> <li>But, we don't know any of these thing!  </li> <li>How can we find these? We are actually facing the inverse problem. </li> <li>We can observe examples of (inputs, outputs) and we want to discover the system itself, or at least parts of it</li> <li>From our domain knowledge an studiyng the system itself, we might be able to make some reasonable assumption:<ul> <li>Number of defective product is a bionomial random variable( but we still don't know its parameter)  </li> <li>There is a relation between daily demand and weekday</li> <li>Relation between y and x is linear(but we don't know what are its coefficients)</li> </ul> </li> <li>To make reasonable assumption about our problem, we shoould:<ul> <li>know and feel structure and properties of mathematical model</li> <li>know and feel structure and properties of our real problem(domain knowledge)</li> </ul> </li> <li>We also have some observations: Data! </li> <li>We have observed the system for many cases of inputs, and recorded its output</li> <li>So we have hundreds(or more, or less) of (inputs, outputs) examples</li> <li>But, all we can do, is probabilistic arguments...</li> <li>Based on our observations, we can judge liklihood of different theories, but we never could make sure judgments</li> <li>If a fund, beats the market 37 weeks in a 52 week year, what can we say about his weekly chance of success?</li> <li>If we observe, each dollar increase in marketing, results in $ 1.5 $ dollar increase in sale...</li> <li>Here is our demand data, what is the distribution of demand? of course, we can not answer this with usuall certainty, we just can make some probabilistic reasoning</li> </ul>"},{"location":"weeks/week08/#probability-to-the-rescue","title":"probability to the rescue","text":"<ul> <li>answer of all of these questions is in probability language, more specifically conditional probability and bayesian perspective</li> <li>You want to really understand results of A/B testing? hypothesis testing?</li> <li>Regression results?</li> <li>Is this distriution good fit to the data?</li> <li>Should I invest in this broker?</li> <li>Is this new change really working?</li> <li>Are we facing a different year? is the shift in demand just a fluctuation or something foundametal has changes?</li> <li>Is this new website design better, or was that sales bump just luck?</li> <li>Did our marketing campaign actually work?</li> <li>Did our marketing campaign actually work?</li> <li>Is this food casuing cancer? </li> <li>Should I change my diet, because of all of these medical studies?</li> <li>DEAD FISH DON\u2019T READ MINDS e</li> </ul>"},{"location":"weeks/week08/#we-need-an-overview-of-scientific-method","title":"we need an overview of scientific method","text":""},{"location":"weeks/week08/#from-reductio-ad-absurdum-to-reductio-ad-unlikely","title":"From Reductio ad absurdum to Reductio ad unlikely","text":"<ul> <li>How can we prove a theory?</li> <li>When we increase our beleife in a theory?</li> <li>If our observation are consistent with the theory?</li> <li>If negation of theory results in contradiction?</li> </ul> <p>To confirm a theory, is it enough that our observation is consistent with that theory?</p>"},{"location":"weeks/week08/#reductio-ad-absurdum","title":"Reductio ad absurdum","text":"<p>To prove a theory $ T $ is true, we consider its negation, call it $ H_0 $ 1. Suppose the negation of target theory is true: $ H_0 $ is true.  2. It follows from $ H_0 $ that a certain fact F cannot be  the case.  3. But F is the case. 4. Therefore, H is false.</p> <ul> <li>basically, we show(deductively) that negation of our target theory is inconsistent with observations(facts)</li> </ul>"},{"location":"weeks/week08/#reductio-ad-unlikely","title":"Reductio ad unlikely","text":"<ol> <li>Suppose the null hypothesis H is true.  </li> <li>It follows from H that a certain outcome O is  very improbable (say, less than Fisher\u2019s 0.05  threshold).</li> <li>But O was actually observed.  </li> <li>Therefore, H is very improbable.</li> </ol>"},{"location":"weeks/week08/#beyond-the-numbers-probabilistic-reasoning-for-business-analytics_1","title":"Beyond the Numbers: Probabilistic Reasoning for Business Analytics","text":""},{"location":"weeks/week08/#understanding-p-values-conditional-probability-and-why-common-sense-is-your-best-tool","title":"Understanding P-values, Conditional Probability, and Why Common Sense is Your Best Tool","text":""},{"location":"weeks/week08/#why-are-we-here-the-analysts-dilemma","title":"Why Are We Here? The Analyst's Dilemma \ud83e\uddd0**","text":"<p>In business, we face constant uncertainty. * Did our marketing campaign actually work? * Is this new website design better, or was that sales bump just luck? * Is this flagged transaction fraudulent or a false alarm?</p> <p>Our goal is to use math as an extension of common sense to make better judgments under uncertainty. This means going beyond just calculating numbers and truly understanding what they mean.</p>"},{"location":"weeks/week08/#a-classical-argument-reductio-ad-unlikely","title":"A Classical Argument: \"Reductio ad Unlikely\"**","text":"<p>This is a powerful form of reasoning used to evaluate a hypothesis.</p> <p>The Logic: 1.  Assume a hypothesis (H) is true. (e.g., \"This star cluster is just a random coincidence.\") 2.  If H is true, a certain outcome (O) would be extremely improbable. (e.g., \"The chance of 6 stars being this close randomly is 1 in 500,000.\") 3.  But, we observed that improbable outcome O! (e.g., \"We see the Pleiades star cluster right there.\") 4.  Conclusion: The initial hypothesis (H) is probably false.</p> <p>[Image of the Pleiades star cluster]</p> <p>This helps us infer that there's an underlying structure or cause, not just random chance.</p>"},{"location":"weeks/week08/#when-unlikely-reasoning-fails","title":"When \"Unlikely\" Reasoning Fails \u26a0\ufe0f**","text":"<p>This logic has critical pitfalls if we're not careful. It's easy to misuse!</p> <ul> <li> <p>The Albino Paradox: Imagine finding one albino in a random group of 50 people.</p> <ul> <li>Hypothesis (H): \"This is a group of human beings.\"</li> <li>Observation (O): We found an albino. This is a very rare event (improbable).</li> <li>Flawed Conclusion: \"Therefore, the hypothesis that they are human is probably false.\"</li> <li>The Lesson: Improbable is not impossible. A rare event doesn't automatically disprove a very plausible hypothesis.</li> </ul> </li> <li> <p>The Bible Codes &amp; Data Mining: People \"found\" predictions in ancient texts by looking for equidistant letter sequences.</p> <ul> <li>The Trap: With enough \"wiggle room\" (changing the skip interval, direction, etc.), you can find any pattern you look for.</li> <li>Business Lesson: This is like \"torturing the data until it confesses.\" If you run enough tests without a clear hypothesis, you're bound to find a statistically significant result by pure chance.</li> </ul> </li> </ul>"},{"location":"weeks/week08/#the-p-value-a-formal-tool-for-unlikely","title":"The P-value: A Formal Tool for \"Unlikely\"**","text":"<p>The p-value is a cornerstone of statistical testing, used everywhere from medicine to marketing.</p> <ul> <li> <p>Null Hypothesis ($ H_0 $): The \"skeptic's\" hypothesis. It assumes no effect.</p> <ul> <li>\"The new drug has no effect.\"</li> <li>\"The ad campaign did not increase sales.\"</li> <li>\"There is no difference between website A and website B.\"</li> </ul> </li> <li> <p>P-value Definition: The probability of seeing our observed data (or something even more extreme), assuming the null hypothesis ($ H_0 $) is true.</p> <ul> <li>$ p = P(\\text{Observed Data or more extreme} | H_0 \\text{ is true}) $</li> </ul> </li> <li> <p>P-value if a measure of surprise! it basically shows how surpring given extremness of our observation is</p> </li> <li> <p>The Magic Threshold: Conventionally, if $ p &lt; 0.05 $, we call the result \"statistically significant\" This suggests the outcome was too unlikely to have occurred by random chance alone, so we reject the null hypothesis.</p> </li> </ul>"},{"location":"weeks/week08/#p-values-in-business-ab-testing","title":"P-values in Business: A/B Testing**","text":"<p>P-values are crucial for making data-driven decisions.</p> <p>Scenario: You're running an A/B test on your website.</p> <ul> <li>Version A: The original button.</li> <li>Version B: A new, bright green button.</li> <li>Null Hypothesis ( $ H_0 $ ): The button color has no effect on clicks. ($ Conversion_A = Conversion_B $)</li> </ul> <p>Results: Version B gets more clicks. You run a statistical test and get a p-value of 0.03.</p> <p>Interpretation:</p> <ul> <li>Since $ 0.03 &lt; 0.05 $ , the result is statistically significant.</li> <li>There is only a 3% chance you would see this difference in clicks (or a larger one) if the green button truly had no effect.</li> <li>Decision: You can be reasonably confident(how much) the effect is real. You reject $ H_0 $ and implement the green button.</li> </ul> <p>Question: How confident are you that the effect is reall? How likely? What is the probability that effect is real?  </p>"},{"location":"weeks/week08/#the-prosecutors-fallacy-the-base-rate-fallacy","title":"The Prosecutor's Fallacy &amp; The Base Rate Fallacy","text":"<p>Scenario: A crime is committed. DNA evidence at the scene matches a suspect. * The chance of a random person matching the DNA is 1 in 10,000. (This is like a p-value).</p> <p>The Prosecutor's Argument: \"The chance of a random match is 1 in 10,000. Therefore, there is only a 1 in 10,000 chance the suspect is innocent.\" WRONG.</p>"},{"location":"weeks/week08/#the-1-most-dangerous-mistake-with-p-values","title":"The #1 Most Dangerous Mistake with P-values!**","text":"<p>This is the single most important concept to understand. It's all about conditional probability.</p> <p>A p-value tells you:</p> <ul> <li>$ P(\\text{Data} | H_0 \\text{ is True}) $ -&gt; The probability of seeing the evidence, assuming the person is innocent.</li> </ul> <p>What you want to know is:</p> <ul> <li>$ P(H_0 \\text{ is True} | \\text{Data}) $ -&gt; The probability the person is innocent, given the evidence.</li> </ul> <p>These are NOT the same thing! Confusing them is called the Prosecutor's Fallacy.</p>"},{"location":"weeks/week08/#the-prosecutors-fallacy-the-base-rate-fallacy_1","title":"The Prosecutor's Fallacy &amp; The Base Rate Fallacy**","text":"<p>Scenario: A crime is committed. DNA evidence at the scene matches a suspect. * The chance of a random person matching the DNA is 1 in 10,000. (This is like a p-value).</p> <p>The Prosecutor's Flawed Argument: \"The chance of a random match is 1 in 10,000. Therefore, there is only a 1 in 10,000 chance the suspect is innocent.\" WRONG.</p> <p>Why it's wrong: The Base Rate Fallacy</p> <ul> <li>The prosecutor ignores the base rate: How many people could have been at the crime scene?</li> <li>If the crime was in a city of 1,000,000 people, you'd expect about 100 people to match the DNA by pure chance!</li> <li>The DNA evidence tells you the suspect is one of those 100 people, not that they are 99.99% guilty.</li> </ul>"},{"location":"weeks/week08/#statistical-significance-practical-importance","title":"Statistical Significance \u2260 Practical Importance \ud83d\udcb0**","text":"<p>A \"significant\" result doesn't mean it's a meaningful result.</p> <p>The Birth Control Scare Example:</p> <ul> <li>A study found a new birth control pill \"doubled the risk\" of a blood clot (thrombosis). This was a statistically significant finding ($ p &lt; 0.05 $).</li> <li>Panic ensued, and many women stopped taking it.</li> <li>The Missing Context: The original risk was incredibly small (1 in 7,000). Doubling it made it 2 in 7,000. The risk of getting a blood clot from pregnancy was far higher! The \"significant\" result was not practically important.</li> </ul> <p>Business Lesson: A marketing change might produce a statistically significant 0.01% lift in sales. But is that tiny lift worth the cost of the campaign? Always ask about the size of the effect and the ROI.</p>"},{"location":"weeks/week08/#the-analysts-wiggle-room-p-hacking-bias","title":"The Analyst's \"Wiggle Room\": P-Hacking &amp; Bias**","text":"<p>Pressure to find \"significant\" results can lead to bad science.</p> <ul> <li>P-hacking: Trying different things (deleting outliers, adding variables, stopping the test at a convenient time) until you get a $ p &lt; 0.05 $. This is cheating.</li> <li>File Drawer Problem: Studies with non-significant (\"boring\") results often don't get published or shared. We only see the successes, which makes effects look more robust than they really are.</li> </ul> <p>This creates a distorted view of reality and leads to investing in ideas that only worked due to luck. Be skeptical of amazing, one-off results. Demand replication!</p>"},{"location":"weeks/week08/#a-more-intuitive-way-bayesian-inference","title":"A More Intuitive Way: Bayesian Inference \ud83e\udde0**","text":"<p>While p-values are common, Bayesian thinking is often closer to how we naturally reason.</p> <ul> <li>P-values ask: \"How surprising is this data, assuming my hypothesis is wrong?\"</li> <li>Bayesian Inference asks: \"Given the data I just saw, how much should I update my belief in my hypothesis?\"</li> </ul> <p>It lets you formally combine: * Prior Belief: What you thought before the experiment (e.g., \"I'm 30% sure this new ad will work based on past campaigns.\") * Evidence: The data from your test. * Posterior Belief: Your updated belief after seeing the data.</p> <p>This directly answers the question managers care about: \"How likely is it that this is working?\"</p>"},{"location":"weeks/week08/#your-toolkit-as-a-smart-analyst","title":"Your Toolkit as a Smart Analyst \ud83d\udee0\ufe0f**","text":"<p>Your job is to provide wisdom, not just numbers.</p> <ol> <li>Use P-values as a Detective, Not a Judge: A low p-value is a clue that something interesting might be happening. It's a starting point for more investigation, not the final verdict.</li> <li>Mind Your Conditionals: Always be clear if you're talking about $ P(\\text{Data} | \\text{Hypothesis}) $ or $ P(\\text{Hypothesis} | \\text{Data}) $.</li> <li>Context is King: Never forget the base rate. A result is meaningless without context. How big is the effect? What's the ROI?</li> <li>Stay Skeptical: Be aware of p-hacking and the file drawer problem. One study is just one study. Is there corroborating evidence? Can it be replicated?</li> </ol> <p>By mastering these principles, you move from being a data cruncher to a trusted strategic advisor.</p>"},{"location":"weeks/week09/","title":"Prepare for Week 9","text":""},{"location":"weeks/week09/#main-concepts-of-data-operations-in-relational-database","title":"Main Concepts of Data Operations in Relational Database","text":""},{"location":"weeks/week09/#slide-1-data-as-rows-and-columns","title":"Slide 1 \u2014 Data as Rows and Columns","text":"<ul> <li> <p>Table as universal structure:</p> <ul> <li> <p>Rows = individuals, data units, or samples.</p> </li> <li> <p>Columns = attributes, variables, or measurements.</p> </li> </ul> </li> <li> <p>Rows represent individual records or observations. Think of a row as a single \"case \"such as a customer, a product, or a specific transaction. Every row is a distinct entity</p> </li> <li> <p>Columns represent different attributes or fields for each record. For example, in a table of customers, you might have columns for <code>Customer_ID</code>, <code>Age</code>, <code>City</code>, and <code>Total_Purchases</code> </p> </li> </ul> <p>Idea It is useful to think as Each column as a vector, which shows one variable across many  observations.</p> <p>\ud83d\udca1 Think \u201crows = cases, columns = features.\u201d</p>"},{"location":"weeks/week09/#slide-2-understanding-data-and-variable-types","title":"Slide 2: Understanding Data and Variable Types","text":"<p>Data is not just numbers; it comes in various types, and each type dictates what operations you can perform.</p> <ul> <li> <p>Numerical:</p> <ul> <li> <p>Discrete: Whole numbers (e.g., number of items purchased).</p> </li> <li> <p>Continuous: Any number within a range (e.g., temperature, height).</p> </li> </ul> </li> </ul> <p>\ud83d\udca1 Not all numeric variables should be treated as mathematical numbers in mathematical operations</p> <ul> <li> <p>Text (String):</p> <ul> <li>Unstructured text (e.g., a product description).</li> </ul> </li> <li> <p>Boolean:</p> <ul> <li> <p>Values are either <code>TRUE</code> or <code>FALSE</code> (e.g., <code>is_customer</code>).</p> </li> <li> <p>In calculations, <code>TRUE</code> is often treated as <code>1</code> and <code>FALSE</code> as <code>0</code>, allowing for powerful filtering and counting.</p> </li> </ul> </li> <li> <p>Categorical:</p> <ul> <li> <p>Values are a fixed set of categories (e.g., 'Male'/'Female', 'North'/'South'/'East'/'West').</p> </li> <li> <p>Can be represented as text or numbers (e.g., <code>0</code> for 'Male', <code>1</code> for 'Female'), but the numbers have no mathematical meaning themselves.</p> </li> </ul> </li> <li> <p>Date Time</p> </li> </ul> <p>Understanding these types is crucial for preparing data for analysis and choosing the right functions.</p> <p>\ud83d\udca1 Knowing the type matters: it defines what(and how) operations make sense.</p>"},{"location":"weeks/week09/#slide-3-the-two-pillars-of-data-manipulation","title":"Slide 3: The Two Pillars of Data Manipulation","text":"<p>Data manipulation primarily involves two core types of operations:</p> <ol> <li> <p>Querying (Filtering) Data: This operation selects a subset of rows (individuals, samples) from a table based on conditions applied to one or more columns (attributes).</p> <ul> <li> <p>Concept: You're not changing the data itself, but rather isolating the records of interest.</p> </li> <li> <p>Example: <code>SELECT * FROM Sales WHERE Region = 'North' AND Total_Sales &gt; 1000</code>. This returns all columns for a select group of rows that meet the criteria.</p> </li> </ul> </li> <li> <p>Transforming Data: This operation applies a function to one or more columns to create a new output. The output can be of the same shape as the input or a different shape.</p> </li> </ol> <p>\ud83d\udca1 Transformation = new variable from old ones</p> <p>\ud83d\udca1 Transformations and queries are done using functions and operations    </p> <p>\ud83d\udca1 Operations could be seen as functions too</p>"},{"location":"weeks/week09/#slide-4-a-data-manipulation-overview-in-sql","title":"Slide 4: A Data Manipulation Overview in SQL","text":"<p>SQL (Structured Query Language) is the standard language for managing and querying relational databases. It brings together all the concepts we've discussed into a single, powerful syntax.</p>"},{"location":"weeks/week09/#key-sql-operations","title":"Key SQL Operations:","text":"<ul> <li> <p><code>SELECT</code>: The command for querying. You specify which columns you want to retrieve.</p> </li> <li> <p><code>FROM</code>: Indicates the table you are querying.</p> </li> <li> <p><code>WHERE</code>: Filters the rows based on logical conditions. This is the filtering or querying step.</p> </li> <li> <p><code>GROUP BY</code>: A command used for aggregation. It groups rows that have the same values in specified columns (e.g., <code>GROUP BY Region</code>).</p> </li> <li> <p><code>ORDER BY</code>: Sorts the results.</p> </li> </ul> <p>This structured approach allows us to think abstractly about the operations we perform in tools like Excel, Power BI, or Python, understanding that they are all built on these same fundamental principles.</p>"},{"location":"weeks/week09/#slide-5-the-function-as-a-transformation-input-output","title":"Slide 5: The Function as a Transformation: Input \u2192 Output","text":"<p>Every operation we perform on data, from a simple calculation to a complex model, can be thought of as a function with a defined input and a defined output.</p>"},{"location":"weeks/week09/#key-idea","title":"Key Idea:","text":"<p>Understanding the type and dimension of the input and output is critical for thinking about data operations abstractly.</p> <ul> <li> <p>Scalar: A single value (e.g., the number 5, the word 'apple').</p> </li> <li> <p>Vector (Array): A one-dimensional list of values of single variable (e.g., a single column of data).</p> <ul> <li>the condition of single variable is not strictly necessary, it is just for better conceptual understanding</li> </ul> </li> <li> <p>Table (Matrix): A two-dimensional collection of rows and columns (e.g., an entire dataset).</p> </li> <li> <p>Arrays or tensors with higher dimensions:  n-dimensional array of data </p> </li> </ul> <p>This framework helps you anticipate what a function will do and how its output will interact with other data.</p>"},{"location":"weeks/week09/#slide-6-functions-as-input-output","title":"Slide 6 \u2014 Functions as Input \u2192 Output","text":"<p>Think about type and shape of input and output.</p> <ol> <li> <p>Scalar \u2192 Scalar</p> <ul> <li> <p><code>f(x) = x^2</code>, <code>log(x)</code>.</p> </li> <li> <p>Apply to single numbers.</p> </li> </ul> </li> <li> <p>Multi-scalar \u2192 Scalar</p> <ul> <li><code>f(x,y) = x+y</code>, <code>max(x,y)</code>,  <code>profit(order, demand)</code></li> </ul> </li> <li> <p>Vector \u2192 Vector (same shape)</p> <ul> <li>Apply elementwise: <code>7*A1:A8</code>, <code>log(Salary)</code> , <code>Age+5</code> where <code>Salary</code> and <code>Age</code> are columns</li> </ul> </li> <li> <p>Vector \u2192 Scalar (aggregate)</p> <ul> <li><code>SUM(A1:A8)</code>, <code>mean(Age)</code>, <code>sum(Sales)</code></li> <li><code>SUBTOTAL(1, A1:A8)</code></li> </ul> </li> <li> <p>Multi-vector \u2192 Vector</p> <ul> <li>Row-wise computation: <code>A1:A8*B1:B8</code>, <code>Profit = Revenue \u2013 Cost</code>.</li> </ul> </li> <li> <p>This elementwise computation logic is generalized into multi dimensional arrays and tensors        </p> </li> </ol> <p>\ud83d\udca1 Understanding input/output types clarifies how functions behave on data.</p>"},{"location":"weeks/week09/#slide-7-main-operations-on-data","title":"Slide 7 \u2014 Main Operations on Data","text":"<ol> <li> <p>Query rows:</p> <ul> <li> <p>Select individuals with conditions on attributes.</p> </li> <li> <p>Examples:</p> <ul> <li> <p><code>Age &gt; 30</code></p> </li> <li> <p><code>Department = \"Sales\"</code></p> </li> </ul> </li> <li> <p>SQL: <code>SELECT * FROM Employees WHERE Age &gt; 30;</code></p> </li> </ul> </li> <li> <p>Transform columns (vectors):</p> <ul> <li> <p>Apply functions to variables.</p> </li> <li> <p>Examples: scaling salaries, taking logarithms, computing new ratios.</p> </li> </ul> </li> <li> <p>Aggregate:</p> <ul> <li> <p>Collapse many values into a summary (scalar).</p> </li> <li> <p>Examples: <code>SUM(Salary)</code>, <code>AVG(Age)</code>, <code>COUNT(Department)</code>.</p> </li> </ul> </li> </ol>"},{"location":"weeks/week09/#slide-8-querying-and-filtering-data","title":"Slide 8: Querying and Filtering Data","text":"<p>One of the most fundamental operations is querying, which involves selecting a subset of data based on specific conditions. This is how you narrow down your focus to the records that matter.</p>"},{"location":"weeks/week09/#the-power-of-logical-conditions","title":"The Power of Logical Conditions","text":"<ul> <li> <p>You define conditions using logical operators: <code>WHERE</code>, <code>AND</code>, <code>OR</code>, <code>NOT</code>.</p> </li> <li> <p>These conditions evaluate to <code>TRUE</code> or <code>FALSE</code> for each row.</p> </li> <li> <p>The query then filters the table, keeping only the rows where the condition is <code>TRUE</code>.</p> </li> </ul> <p>Example: <code>SELECT * FROM Orders WHERE Region = 'North' AND Total_Sales &gt; 1000</code>. This query returns only the rows for orders in the 'North' region with sales greater than $1,000.</p>"},{"location":"weeks/week09/#slide-9-querying-examples","title":"Slide 9 \u2014 Querying examples","text":"<ul> <li> <p>Filtering is based on Boolean conditions.</p> </li> <li> <p>Example dataset:</p> </li> </ul> Name Age Salary Dept Ali 25 4000 Sales Sara 38 6500 HR Reza 42 7200 Sales <ul> <li> <p>Query: <code>Age &gt; 30 AND Dept = 'Sales'</code>.</p> </li> <li> <p>Result: only rows that satisfy both conditions.</p> </li> </ul> <p>Excel: filters, IF functions. SQL: <code>WHERE</code> clause. Pandas: <code>df[df.Age &gt; 30 &amp; (df.Dept==\"Sales\")]</code>.</p>"},{"location":"weeks/week09/#slide-10-transforming-columns","title":"Slide 10 \u2014 Transforming Columns","text":"<ul> <li>Apply a function to a whole column (vector):</li> </ul> <p>Examples:</p> <ul> <li> <p><code>Salary * 1.1</code> (raise by 10%).</p> </li> <li> <p><code>log(Sales)</code>.</p> </li> <li> <p><code>HoursWorked / Sales</code> (new variable).</p> </li> </ul> <p>Excel: formula drag. SQL: <code>SELECT Salary*1.1 AS NewSalary</code>. Pandas: <code>df[\"Salary\"] * 1.1</code>.</p> <p>\ud83d\udca1 Transformation = new variable from old ones.</p>"},{"location":"weeks/week09/#slide-11-aggregation-summarizing-data","title":"Slide 11: Aggregation: Summarizing Data","text":"<p>Aggregation is the process of applying a function to a group of values to produce a single summary value. This is how we get a high-level view of our data.</p> <ul> <li> <p>Common Aggregation Functions:</p> <ul> <li> <p><code>SUM</code>: Adds up all values.</p> </li> <li> <p><code>AVERAGE</code> (<code>AVG</code>): Calculates the mean.</p> </li> <li> <p><code>COUNT</code>: Tallies the number of records.</p> </li> <li> <p><code>MAX</code> and <code>MIN</code>: Finds the highest and lowest values.</p> </li> </ul> </li> </ul> <p>These operations are often performed on groups of data, for example, finding the average sales for each region or the total number of customers for each product category.</p>"},{"location":"weeks/week09/#slide-12-aggregate-operations-examples","title":"Slide 12 \u2014 Aggregate Operations examples","text":"<ul> <li> <p>Collapse a vector into a single summary scalar:</p> <ul> <li><code>SUM</code>, <code>AVG</code>, <code>COUNT</code>, <code>MIN</code>, <code>MAX</code>, <code>MEDIAN</code>, <code>MODE</code>.</li> </ul> </li> <li> <p>SQL:</p> <pre><code>SELECT AVG(Salary) FROM Employees;\n</code></pre> </li> <li> <p>Excel: <code>=AVERAGE(SalaryRange)</code>.</p> </li> <li> <p>Pandas: <code>df[\"Salary\"].mean()</code>.</p> </li> </ul> <p>\ud83d\udca1 Aggregation reduces dimensionality: many values \u2192 one.</p>"},{"location":"weeks/week09/#slide-13-the-logic-of-true-and-false","title":"Slide 13: The Logic of <code>TRUE</code> and <code>FALSE</code>","text":"<p>Logical operations are at the heart of filtering and conditioning. In many programming languages and data systems, <code>TRUE</code> and <code>FALSE</code> have a numerical representation.</p>"},{"location":"weeks/week09/#numerical-representation","title":"Numerical Representation","text":"<ul> <li> <p><code>TRUE</code> is represented by the number 1.</p> </li> <li> <p><code>FALSE</code> is represented by the number 0.</p> </li> </ul>"},{"location":"weeks/week09/#practical-implications","title":"Practical Implications","text":"<ul> <li> <p>This allows you to perform mathematical operations on logical results. For example, <code>SUM(C2:C100)</code> on a column of <code>TRUE</code>/<code>FALSE</code> values would count the number of <code>TRUE</code>s.</p> </li> <li> <p>Conversely, in some systems, <code>0</code> is treated as <code>FALSE</code>, and any other number (positive or negative) is treated as <code>TRUE</code>.</p> </li> </ul> <p>Be careful! While you can <code>SUM</code> logical values, functions like <code>SUMPRODUCT</code> in Excel may not work as expected on <code>TRUE</code> and <code>FALSE</code> directly and often require a conversion, such as <code>(--)</code> or <code>N()</code>, to convert them into <code>1</code>s and <code>0</code>s. This highlights the importance of understanding how different tools handle data types.</p>"},{"location":"weeks/week09/#slide-14-excels-secret-to-vectorized-thinking","title":"Slide 14: Excel's Secret to Vectorized Thinking","text":"<p>Excel's user interface, while seeming simple, is a masterclass in performing vectorized operations without the jargon.</p> <ul> <li> <p>The Drag-and-Fill Handle: When you write a formula in a single cell (e.g., <code>=A2*B2</code>) and drag the fill handle down, you are essentially telling Excel to apply that same operation to every subsequent row.</p> </li> <li> <p>Vectorized Computation: Excel isn't just copying the formula; it's efficiently applying the logic to the entire range of cells, effectively operating on the <code>A</code> and <code>B</code> columns as vectors to produce a new <code>C</code> column vector.</p> </li> </ul> <p>This intuitive process prepares your mind for the vectorized thinking that is fundamental to languages like Python (with libraries like Pandas and NumPy) and R.</p>"},{"location":"weeks/week09/#slide-15-the-evolution-of-excels-computation-engine","title":"Slide 15: The Evolution of Excel's Computation Engine","text":"<p>Excel's \"drag-and-fill\" method, while intuitive, was a row-by-row, cell-based approach. The new dynamic array engine represents a paradigm shift to truly vectorized computation.</p> <ul> <li>The Old Way: In the past, you'd write a formula in one cell and drag it down a column. Excel would then copy that formula, essentially treating each cell as a separate calculation. This was inefficient for large datasets.</li> <li>The New Way (Dynamic Arrays): With dynamic arrays, a single formula entered in one cell can spill its results into multiple adjacent cells. This means you are writing a single vectorized formula that operates on an entire range of data at once.</li> </ul> <p>This is a fundamental change from a scalar-oriented mindset (one cell, one value) to a vector-oriented mindset (one formula, multiple values). This makes complex calculations simpler, more readable, and significantly more efficient.</p>"},{"location":"weeks/week09/#new-functions-and-formulas","title":"New Functions and Formulas","text":"<p>The dynamic array engine introduces new functions designed for this vectorized approach:</p> <ul> <li><code>FILTER</code>: Returns a filtered range of data based on criteria you define. Instead of a complex <code>INDEX</code>/<code>MATCH</code> formula, you can write <code>FILTER(data_range, criteria_range)</code>.</li> <li><code>SORT</code>: Sorts a range of data based on a specified column. It's much simpler than the old method of sorting a range.</li> <li><code>UNIQUE</code>: Returns a list of unique values from a range. This saves you from having to use <code>PivotTables</code> or manual data cleaning.</li> <li><code>XLOOKUP</code>: A more powerful and flexible replacement for <code>VLOOKUP</code> and <code>HLOOKUP</code>.</li> </ul> <p>These functions operate on entire arrays, making your spreadsheets more robust and easier to manage, truly preparing you for vectorized thinking in more advanced data analysis tools.</p> <p>I can create a new set of slides that explains how <code>GROUP BY</code> is handled in both Excel and Pandas, and connects the concepts to the core <code>split-apply-combine</code> methodology.</p>"},{"location":"weeks/week09/#slide-16-grouping-data-summarizing-by-category","title":"Slide 16: Grouping Data: Summarizing by Category","text":"<p>Often, you don't want to analyze every individual record. Instead, you want to get a high-level view by summarizing data based on a category. This operation is known as grouping. </p>"},{"location":"weeks/week09/#the-core-idea","title":"The Core Idea","text":"<p>The goal is to take a detailed table and condense it into a new, smaller table that shows an aggregated value for each unique group. This is the essence of data reporting and analysis.</p> <ul> <li>Example: How many orders did each customer place? What was the total revenue for each product category?</li> </ul> <p>Both Excel and more advanced data tools like Pandas have powerful ways to perform this operation.</p>"},{"location":"weeks/week09/#slide-17-the-excel-group-by-the-power-of-the-pivottable","title":"Slide 17: The Excel <code>GROUP BY</code> - The Power of the PivotTable","text":"<p>In Excel, the most famous tool for grouping data is the PivotTable. It provides a user-friendly, drag-and-drop interface for what is, under the hood, a complex data operation.</p> <ol> <li>Split: You drag a field (like <code>Region</code>) into the \"Rows\" or \"Columns\" area. Excel automatically identifies every unique value and creates a new row or column for each one. This is the splitting step.</li> <li>Apply (Aggregate): You then drag a numerical field (like <code>Sales</code>) into the \"Values\" area. Excel applies an aggregate function to each group. By default, it's <code>SUM</code>, but you can change it to <code>COUNT</code>, <code>AVERAGE</code>, <code>MAX</code>, or <code>MIN</code>.</li> <li>Combine: The PivotTable then presents the final, summarized table, which is the result of applying the aggregate function to each group.</li> </ol> <p>This simple workflow performs the full <code>split-apply-combine</code> process that is central to data analysis. </p>"},{"location":"weeks/week09/#slide-18-the-pandas-group-by-split-apply-combine","title":"Slide 18: The Pandas <code>GROUP BY</code> - <code>split-apply-combine</code>","text":"<p>In the Python world, the Pandas library provides a more explicit and powerful way to perform grouping, formalized by the <code>split-apply-combine</code> methodology.</p> <ol> <li>Split: The <code>df.groupby('column_name')</code> method is the splitting step. It creates a special object that logically separates the <code>DataFrame</code> into sub-groups without creating copies.<ul> <li>Example: <code>df.groupby('Region')</code></li> </ul> </li> <li>Apply: You then chain an aggregate function to this object. This is the applying step, where the function is executed on each of the groups.<ul> <li>Example: <code>.sum()</code>, <code>.mean()</code>, <code>.count()</code>, or even a custom function.</li> </ul> </li> <li>Combine: Pandas takes the results from each group and combines them back into a new <code>DataFrame</code> or <code>Series</code>. The final output is a clean, summarized table.</li> </ol> <p>This explicit syntax makes it easy to read and understand exactly what is happening to your data, which is essential for reproducibility and automation. </p>"},{"location":"weeks/week09/#slide-19-why-grouping-is-a-fundamental-concept","title":"Slide 19: Why Grouping is a Fundamental Concept","text":"<p>Understanding grouping is a major step toward thinking abstractly about data. It's the operation that lets you move from looking at individual records to identifying trends and patterns across your dataset.</p> <ul> <li>Business Intelligence: Grouping is the basis for all dashboards and reports, allowing you to quickly see total sales by month, customer counts by city, or average order value by product type.</li> <li>Data Cleaning: You can use <code>GROUP BY</code> to quickly check for duplicates or find unique values, which is a critical part of data preparation.</li> <li>Data Science: In machine learning, grouping is used for feature engineering, where you create new variables by aggregating data. For example, you might create a <code>total_purchases</code> variable for each customer from a transaction log.</li> </ul> <p>By mastering this concept, you are no longer just looking at a spreadsheet; you are thinking about data at a higher, more strategic level.</p> <p>Yes, you are absolutely right. Decision trees are fundamentally about finding the \"best\" way to group data for prediction. They do this by recursively partitioning the dataset into smaller, more homogeneous subsets based on the values of the input features.</p> <p>Here are some slides that expand on this concept.</p>"},{"location":"weeks/week09/#slide-20-decision-trees-and-the-art-of-grouping-for-prediction","title":"Slide 20: Decision Trees and the Art of Grouping for Prediction","text":"<p>A decision tree is a predictive model that uses a series of simple, logical rules to predict an outcome. It works by repeatedly splitting the data into groups that are as pure as possible with respect to the target variable.</p> <ul> <li>The Core Idea: Imagine you want to predict if a customer will buy a product. A decision tree might first split customers into two groups: those with an income over $50,000 and those with an income below. It then repeats this process on each of those new groups, perhaps splitting again based on age.</li> <li>Recursive Partitioning: The tree continues this process of recursive partitioning until it reaches a point where each final group (a \"leaf\") contains records that are very similar to each other in terms of the outcome.</li> </ul> <p>This method of repeatedly finding the best way to group the data is how a decision tree learns to make predictions. </p>"},{"location":"weeks/week09/#slide-21-the-logic-of-splitting-how-trees-find-the-best-groups","title":"Slide 21: The Logic of Splitting: How Trees Find the \"Best\" Groups","text":"<p>The \"best\" split is the one that results in the most homogeneous or \"pure\" child nodes. But how does the tree measure purity?</p> <ul> <li>Purity Metrics: Decision trees use mathematical functions to evaluate the quality of a split. Common metrics include:<ul> <li>Gini Impurity: Measures how often a randomly chosen element from the set would be incorrectly labeled if it were randomly labeled according to the distribution of labels in the subset. A Gini score of 0 means perfect purity (all elements belong to the same class).</li> <li>Entropy: A concept from information theory that measures the disorder or randomness in a set of data. A split that reduces entropy the most is considered the best.</li> </ul> </li> <li>The Goal: At each step, the algorithm evaluates every possible split on every feature and chooses the one that maximizes the reduction in impurity. It\u2019s like finding the single question that gives you the most information about the outcome.</li> </ul> <p>The result is a set of rules (the tree's path) that lead you from the initial data to a final prediction by narrowing down the data into highly pure groups.</p>"},{"location":"weeks/week09/#slide-22-from-groups-to-predictions","title":"Slide 22: From Groups to Predictions","text":"<p>Once the decision tree is built, making a prediction for a new, unseen data point is a straightforward process of following the rules.</p> <ul> <li>Classification: For a classification task (predicting a category, like <code>yes/no</code> or <code>buy/don't buy</code>), you simply drop the new data point down the tree. At each node, you check the condition and follow the appropriate branch. When you reach a leaf node, the prediction is the most common class in that final group.</li> <li>Regression: For a regression task (predicting a numerical value, like price or sales), the process is the same. The prediction at the leaf node is typically the average of all the values in that final group.</li> </ul> <p>This intuitive process makes decision trees easy to understand and interpret, as the \"decision-making\" process is transparent and based on simple groupings of your data.</p>"}]}